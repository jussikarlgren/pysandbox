{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import corenlp\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality=2000\n",
    "denseness=10//dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseadd(onevec,othvec,weight=1,normalised=False):\n",
    "    if normalised:\n",
    "        onevec = normalise(onevec)\n",
    "        othvec = normalise(othvec)        \n",
    "    result={}\n",
    "    try:\n",
    "        for l in onevec:\n",
    "            result[l] = onevec[l]\n",
    "        for k in othvec:\n",
    "            if k in result:\n",
    "                result[k] = result[k]+othvec[k]*float(weight)\n",
    "            else:\n",
    "                result[k] = othvec[k]*float(weight)\n",
    "    except:\n",
    "        print(\"sparseadd(): error\")\n",
    "        raise\n",
    "    return result\n",
    "def sparsemultiply(onevec,othvec,weight=1):\n",
    "    result={}\n",
    "    try:\n",
    "        for l in onevec:\n",
    "            if l in othvec:\n",
    "                result[l] = onevec[l]*othvec[l]*float(weight)\n",
    "    except:\n",
    "        print(\"sparsemultiply(): error \")\n",
    "    return result\n",
    "def sparsexor(onevec,othvec):\n",
    "    result={}\n",
    "    try:\n",
    "        for l in range(len(onevec)):\n",
    "            if ((l in onevec) and not (l in othvec)):\n",
    "                result[l] = 1\n",
    "            if (not (l in onevec) and (l in othvec)):\n",
    "                result[l] = 1        \n",
    "    except:\n",
    "        print(\"sparsexor(): error \")\n",
    "    return result\n",
    "\n",
    "def newrandomvector(n,denseness):\n",
    "    vec = {}\n",
    "    k = int(n * denseness)\n",
    "    if k % 2 != 0:\n",
    "        k += 1\n",
    "    if (k > 0):# no need to be careful about this, right? and k % 2 == 0):\n",
    "        nonzeros = random.sample(list(range(n)),k)\n",
    "        negatives = random.sample(nonzeros,k//2)\n",
    "        for i in nonzeros:\n",
    "            vec[str(i)] = 1;\n",
    "        for i in negatives:\n",
    "            vec[str(i)] = -1;\n",
    "    return vec\n",
    "\n",
    "def newoperator(n):\n",
    "    k = 0.1\n",
    "    return newrandomvector(n,k)\n",
    "\n",
    "def sparsecosine(xvec,yvec,rounding=True,decimals=4):\n",
    "    x2 = 0\n",
    "    y2 = 0\n",
    "    xy = 0\n",
    "    try:\n",
    "        for i in xvec:\n",
    "            x2 += xvec[i]*xvec[i]\n",
    "    except KeyError:\n",
    "        print(\"sparsecosine(): error at position \",i)\n",
    "    try:\n",
    "        for j in yvec:\n",
    "            y2 += yvec[j]*yvec[j]\n",
    "            if j in xvec:\n",
    "                xy += xvec[j]*yvec[j]\n",
    "    except:\n",
    "        print(\"sparsecosine(): errors at position \",j)\n",
    "    if (x2*y2 == 0):\n",
    "        cos = 0\n",
    "    else:\n",
    "        cos = xy/(math.sqrt(x2)*math.sqrt(y2))\n",
    "    if (rounding):\n",
    "        cos=round(cos,decimals)\n",
    "    return cos\n",
    "\n",
    "def sparselength(vec,rounding=True):\n",
    "    x2 = 0\n",
    "    length=0\n",
    "    try:\n",
    "        for i in vec:\n",
    "            x2 += vec[i]*vec[i]\n",
    "    except:\n",
    "        print(\"sparselength(): error at position \",i)\n",
    "    if (x2 > 0):\n",
    "        length = math.sqrt(x2)\n",
    "    if (rounding):\n",
    "        length=round(length,4)\n",
    "    return length\n",
    "\n",
    "def comb(vec,k=0.1):\n",
    "    newvector={}\n",
    "    n=int(k*dimensionality/2)\n",
    "    sorted_items=sorted(vec.items(), key=lambda x:x[1])\n",
    "    bot=sorted_items[:n]\n",
    "    top=sorted_items[-n:]\n",
    "    for l in bot:\n",
    "        newvector[l[0]]=l[1]\n",
    "    for l in top:\n",
    "        newvector[l[0]]=l[1]\n",
    "    return newvector\n",
    "\n",
    "def sparsesum(vec):\n",
    "    s=0\n",
    "    for i in vec:\n",
    "        s += float(vec[i])\n",
    "    return s\n",
    "\n",
    "def normalise(vec):\n",
    "    newvector={}\n",
    "    vlen=sparselength(vec,False)\n",
    "    if (vlen > 0):\n",
    "        for i in vec:\n",
    "            newvector[i]=vec[i]/math.sqrt(vlen*vlen)\n",
    "    else:\n",
    "        newvector=vec\n",
    "    return newvector\n",
    "\n",
    "def modify(vec,factor):\n",
    "    newvector={}\n",
    "    for i in vec:\n",
    "        if (random.random() > factor):\n",
    "            newvector[i]=vec[i]\n",
    "        else:\n",
    "            newvector[i]=float(vec[i])*(0.5-random.random())*2.0\n",
    "    return newvector\n",
    "\n",
    "def createpermutation(k):\n",
    "    permutation=random.sample(range(k), k)\n",
    "    return permutation\n",
    "    \n",
    "def permute(vector,permutation):\n",
    "    newvector={}\n",
    "    try:\n",
    "        for i in range(len(permutation)):\n",
    "            if str(i) in vector:\n",
    "                newvector[str(permutation[i])]=vector[str(i)]\n",
    "    except:\n",
    "        newvector=vector\n",
    "        print(\"permute(): no permutation done, something wrong\")\n",
    "    return newvector\n",
    "\n",
    "def vectorsaturation(vector):\n",
    "    d = 0\n",
    "    for c in vector:\n",
    "        d += 1\n",
    "    return d\n",
    "\n",
    "def frequencyweight(word):\n",
    "    try:\n",
    "        w = math.exp(-300*math.pi* globalfrequency[word] / bign)\n",
    "    except KeyError:\n",
    "        w = 0.5\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordspacefile=\"/home/jussi/data/wordspaces/gavagai-news-22-morethan5.wordspace\"\n",
    "fdgtextfile=\"/home/jussi/data/GH95-fdg/950102.sgml.fdg.xml\"\n",
    "unittestfile=\"/home/jussi/data/cooksents.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clause:\n",
    "    cleanuppattern=re.compile(r'[\\.\\'\\!\\*\\?\\+,;\\:\\-\\/]+')\n",
    "    def __init__(self,string):\n",
    "        self.surfacestring=string\n",
    "        self.cleanedutterance=re.sub(clause.cleanuppattern,\"\",string)\n",
    "        self.tokens=self.cleanedutterance.lower().split()\n",
    "        self.agent=None\n",
    "        self.event=None\n",
    "        self.patient=None\n",
    "        self.instrument=None\n",
    "        self.location=None\n",
    "        self.manner=None\n",
    "    def __str__(self):\n",
    "        return self.surfacestring\n",
    "    \n",
    "class referent:\n",
    "    def __init__(self, string):\n",
    "        self.surfacestring=string\n",
    "        self.definite=True\n",
    "        self.number=1\n",
    "        \n",
    "class event:\n",
    "    def __init__(self, string):\n",
    "        self.surfacestring=string    \n",
    "        self.negated=False    \n",
    "        self.adverbial=None    \n",
    "        self.tense=None #past present or future\n",
    "        self.aspect=None #ongoing perfect or pointwise\n",
    "        self.mood=None #indicative, irreal, potential, optative, not, imperative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.parse.stanford import StanfordDependencyParser\n",
    "#path_to_stanford_corenlp = '/usr/share/stanford-corenlp-full/'\n",
    "#parser_jar='stanford-corenlp.jar'\n",
    "#path_to_models = path_to_stanford_corenlp+'models/'\n",
    "#model_jar='stanford-english-corenlp-models.jar'\n",
    "#dependency_parser = StanfordDependencyParser(path_to_jar=path_to_stanford_corenlp+parser_jar, path_to_models_jar=path_to_models+model_jar)\n",
    "\n",
    "parser_client = corenlp.CoreNLPClient(annotators=\"tokenize ssplit pos natlog lemma depparse\".split())\n",
    "    \n",
    "    \n",
    "def semanticdepparse(string,debug=False):\n",
    "    depgraph=parser_client.annotate(string)\n",
    "    utterances=[]\n",
    "    for ss in depgraph.sentence:\n",
    "        utterances.append(semanticdepparseprocess(string,ss,debug))\n",
    "    return utterances\n",
    "        \n",
    "def semanticdepparseprocess(string,ss,debug=False):\n",
    "    utterance=clause(string)\n",
    "    utterance.agent=referent(\"epsilon\")\n",
    "    utterance.patient=referent(\"epsilon\")\n",
    "    utterance.event=event(\"epsilon\")\n",
    "    scratch={}\n",
    "    negated=False\n",
    "    adverbial=None\n",
    "    if debug:\n",
    " #       print(ss)\n",
    "        i=1\n",
    "        print(\"root:\",ss.basicDependencies.root)\n",
    "        for w in ss.token:\n",
    "            print(i,\" \",w.lemma,\" \",w.pos)\n",
    "            i += 1\n",
    "        for e in ss.basicDependencies.edge:\n",
    "            print(e.source,ss.token[e.source-1].lemma,\"-\",e.dep,\"->\",e.target,ss.token[e.target-1].lemma) \n",
    "    i=1\n",
    "    sentenceitems={}\n",
    "    sentencepos={}\n",
    "    for w in ss.token:\n",
    "        if w.lemma not in indexspace:\n",
    "            indexspace[w.lemma] = newrandomvector(dimensionality,denseness)\n",
    "        sentenceitems[i] = w.lemma\n",
    "        sentencepos[i] = w.pos\n",
    "        scratch[i] = False\n",
    "        i += 1\n",
    "    root = ss.basicDependencies.root[0] #only one root for now fix this!\n",
    "    utterance.event=event(sentenceitems[root])  \n",
    "    utterance.event.tense=\"PRESENT\"\n",
    "    if sentencepos[root] == \"VBD\":\n",
    "        utterance.event.tense=\"PAST\" \n",
    "    if sentencepos[root] == \"VBN\":\n",
    "        utterance.event.tense=\"PAST\" \n",
    "    for edge in ss.basicDependencies.edge:\n",
    "        if debug:\n",
    "            print(edge.source,sentenceitems[edge.source],\"-\",edge.dep,\"->\",edge.target,sentenceitems[edge.target])\n",
    "        if edge.dep == 'neg':\n",
    "            negated=True\n",
    "        elif edge.dep == 'nsubj':\n",
    "            utterance.agent=referent(sentenceitems[edge.target])\n",
    "            if edge.target in scratch: \n",
    "                if scratch[edge.target]==\"def\":\n",
    "                    utterance.agent.definite=True\n",
    "                elif scratch[edge.target]==\"indef\":\n",
    "                    utterance.agent.definite=False\n",
    "        elif edge.dep == 'dobj':\n",
    "                utterance.patient=referent(sentenceitems[edge.target])\n",
    "                if edge.target in scratch: \n",
    "                    if scratch[edge.target]==\"def\":\n",
    "                        utterance.patient.definite=True\n",
    "                    elif scratch[edge.target]==\"indef\":\n",
    "                        utterance.patient.definite=False\n",
    "        elif edge.dep == 'advmod':\n",
    "                adverbial=sentenceitems[edge.target]            \n",
    "        elif edge.dep == 'det':\n",
    "                if (sentenceitems[edge.target]==\"a\" or sentenceitems[edge.target]==\"an\"):\n",
    "                    scratch[edge.source]=\"indef\"\n",
    "                elif (sentenceitems[edge.target]==\"the\"):\n",
    "                    scratch[edge.target]=\"def\"\n",
    "        elif edge.dep == 'nmod:poss':\n",
    "                scratch[edge.target]=\"def\"\n",
    "        elif edge.dep == 'aux':\n",
    "                if (sentenceitems[edge.target]==\"have\"):\n",
    "                    scratch['aux']=\"have\"\n",
    "                if (sentenceitems[edge.target]==\"do\"):\n",
    "                    scratch['aux']=\"do\"\n",
    "                    if (sentencepos[edge.target] == \"VBD\"):\n",
    "                        utterance.event.tense = \"PAST\"\n",
    "                if (sentenceitems[edge.target]==\"will\"):\n",
    "                    scratch['aux']=\"will\"\n",
    "                if (sentenceitems[edge.target]==\"shall\"):\n",
    "                    scratch['aux']=\"shall\"\n",
    "    try:\n",
    "        if debug: \n",
    "            print(sentenceitems[root],\" \",sentencepos[root])\n",
    "        if sentencepos[root] == \"VB\" and (scratch['aux'] == \"will\" or scratch['aux'] == \"shall\"):\n",
    "            utterance.event.tense=\"FUTURE\"\n",
    "    except:\n",
    "        print(\"semanticdepparse(): tense situation in \"+string)\n",
    "    try:\n",
    "        utterance.event.adverbial=adverbial\n",
    "    except:\n",
    "        print(\"semanticdepparse(): adverbial blowout in \"+string)\n",
    "    try:\n",
    "        utterance.event.negated=negated\n",
    "    except:\n",
    "        print(\"semanticdepparse(): negation mismatch in \"+string)\n",
    "    return utterance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorspace={}\n",
    "globalfrequency={}\n",
    "indexspace={}\n",
    "associationspace={}\n",
    "\n",
    "def chkwordspace(words,debug=False):\n",
    "    i = 0\n",
    "    for w in words:\n",
    "        if w in vectorspace:\n",
    "                i += 1\n",
    "        else:\n",
    "            if debug:\n",
    "                print(\"chkwordspace(): \",w,\" is new and is now hallucinated.\")\n",
    "            denseness2=0.5\n",
    "            vectorspace[w] = newrandomvector(dimensionality,denseness2)\n",
    "            indexspace[w] = newrandomvector(dimensionality,denseness)\n",
    "            associationspace[w] = newrandomvector(dimensionality,denseness2)  \n",
    "            globalfrequency[w] = 1\n",
    "\n",
    "chkwordspace([\"epsilon\"],True)\n",
    "\n",
    "def wordlikeness(w1,w2):\n",
    "    return sparsecosine(vectorspace[w1],vectorspace[w2])\n",
    "\n",
    "def dowordspacefile(wordspacefile):\n",
    "    linepattern = re.compile(r'^\\(\\\"([\\-\\w]+)\\\"\\s+#S2000([\\d\\,\\-\\.\\-\\+;e]+)*:\\s+#S2000([\\d\\-\\+;\\.e\\,]+)*:\\s+#S2000([\\.\\d\\-\\+;e\\,]+)*:\\s+(\\d+)\\)')\n",
    "    vecpattern = re.compile(r';?(\\d+)([\\+\\-][\\,\\.\\d]+(e-\\d\\d)?)')\n",
    "    alicefile=open(wordspacefile,'r')\n",
    "    global vectorspace\n",
    "    vectorspace={}\n",
    "    global globalfrequency\n",
    "    globalfrequency={}\n",
    "    global indexspace\n",
    "    indexspace={}\n",
    "    global associationspace\n",
    "    associationspace={}\n",
    "    aliceline = alicefile.readline()\n",
    "    a=1\n",
    "    b=0\n",
    "    w=0\n",
    "    global bign = 0\n",
    "    while aliceline:\n",
    "        a = a+1\n",
    "        m=linepattern.match(aliceline)\n",
    "        if m:\n",
    "            token=m.groups()[0]\n",
    "            ind=m.groups()[1]\n",
    "            doc=m.groups()[2]\n",
    "            ctx=m.groups()[3]\n",
    "            freq=int(m.groups()[4])\n",
    "#            if (filtering and token )\n",
    "            try:\n",
    "                sparsevec={}\n",
    "                cells = re.findall(vecpattern,ctx)\n",
    "                for c in cells:\n",
    "                    val = c[1]\n",
    "                    kop=val.translate(str.maketrans(\",\",\".\",\"+\"))\n",
    "                    try:\n",
    "                        sparsevec[c[0]] = float(kop)\n",
    "                    except:\n",
    "                        print(\"weird number: \",kop)\n",
    "                vectorspace[token] = sparsevec\n",
    "                sparsevec={}\n",
    "                cells = re.findall(vecpattern,ind)\n",
    "                for c in cells:\n",
    "                    val = c[1]\n",
    "                    kop=val.translate(str.maketrans(\",\",\".\",\"+\"))\n",
    "                    try:\n",
    "                        sparsevec[c[0]] = float(kop)\n",
    "                    except:\n",
    "                        print(\"weird number: \",kop)\n",
    "                indexspace[token] = sparsevec\n",
    "                globalfrequency[token] = freq\n",
    "                sparsevec={}\n",
    "                w=w+1\n",
    "                bign += freq\n",
    "            except:\n",
    "                print(\"fail: \",token,\" \",a)\n",
    "        else:\n",
    "            b=b+1\n",
    "        aliceline = alicefile.readline()\n",
    "    print(a,\" lines seen; \",w,\" items added \",b,\" items disregarded\")\n",
    "    alicefile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dowordspacefile(wordspacefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterancespace = {}\n",
    "dependencyanalysisstore={}\n",
    "def initunittest(debug=False):\n",
    "    with codecs.open(fulltextfile,\"r\", encoding='utf-8') as infile:\n",
    "        rawtext = infile.read().lower()\n",
    "        rawtext = re.sub('\\n', ' ', rawtext)\n",
    "        rawtext = re.sub('\\\"', ' ', rawtext)\n",
    "        rawtext = re.sub('\\s+', ' ', rawtext)\n",
    "        sents = sent_tokenize(rawtext)\n",
    "        i = 0\n",
    "        for s in sents:\n",
    "            print(s)\n",
    "            wds=nltk.word_tokenize(s)\n",
    "            chkwordspace(wds,debug)\n",
    "            try:\n",
    "                analyses = semanticdepparse(s.lower(),debug)\n",
    "                dependencyanalysisstore[s]=analyses\n",
    "                kk = 0\n",
    "                for analysis in analyses:\n",
    "                    u = utterancevector(analysis,debug)\n",
    "                    if (kk == 0):\n",
    "                        utterancespace[s] = u\n",
    "                    else:\n",
    "                        uttterancespace[s+str(kk)] = u\n",
    "                    kk += 1\n",
    "                i += 1\n",
    "            except:\n",
    "                print(\"****\",s)\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltextfile=\"/home/jussi/data/pan12-clean/clean.12AtrainA1.txt\"\n",
    "initunittest(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rununittest():\n",
    "    for v in utterancespace:\n",
    "        print(\"-------------\")\n",
    "        print(v)\n",
    "        neighbours = {}\n",
    "        for w in utterancespace:\n",
    "            if w == v:\n",
    "                continue\n",
    "            neighbours[w] = sparsecosine(utterancespace[v],utterancespace[w])\n",
    "        ns = sorted(neighbours.items(), key=lambda neighbour:neighbour[1], reverse=True)[0:10]\n",
    "        for ww in ns:\n",
    "                print(\"\\t\",ww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = {}\n",
    "target = sparseadd(target,permute(negationabstract,negationpermutation))\n",
    "wd = \"victor\"\n",
    "target = sparseadd(target,comb(vectorspace[wd]),math.log(bign / globalfrequency[wd]))\n",
    "for w in utterancespace:\n",
    "    cc = sparsecosine(utterancespace[w],target) \n",
    "#    if (cc > 0.1):\n",
    "    if wd in w:\n",
    "        print(cc,\" \",w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparsecosine(vectorspace[\"book\"],vectorspace[\"books\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utterancevector(utterance,debug=False,lexical=True,morphology=True,semanticroles=True,constructional=True):\n",
    "    baremorphology=morphology\n",
    "    combinedmorphology=lexical\n",
    "    uttvec={}\n",
    "    if debug:\n",
    "        debugvec={}\n",
    "    if lexical:     # add in referent, using its context vector meaning more or less the concept it refers to\n",
    "        if (utterance.patient):\n",
    "            uttvec=sparseadd(uttvec, comb(vectorspace[utterance.patient.surfacestring]),frequencyweight(utterance.patient.surfacestring)) #, math.log( bign / globalfrequency[utterance.patient.surfacestring]))\n",
    "        if (utterance.event):\n",
    "            uttvec=sparseadd(uttvec,comb(vectorspace[utterance.event.surfacestring]),frequencyweight(utterance.event.surfacestring)) #, math.log( bign / globalfrequency[utterance.event.surfacestring]))\n",
    "        if (utterance.agent):\n",
    "            uttvec=sparseadd(uttvec,comb(vectorspace[utterance.agent.surfacestring]),frequencyweight(utterance.agent.surfacestring)) #, math.log( bign / globalfrequency[utterance.agent.surfacestring]))\n",
    "    if debug:\n",
    "        print(\"utterancevec() lexicon: \",sparsecosine(uttvec,debugvec))\n",
    "        debugvec=uttvec\n",
    "    if morphology:     # add in morphological information about the roles of the referent\n",
    "        morphvec={}\n",
    "        if (utterance.agent):\n",
    "            if (utterance.agent.definite):\n",
    "                morphvec=sparseadd(morphvec,permute(indexspace[utterance.agent.surfacestring],definitepermutation))\n",
    "            else:\n",
    "                morphvec=sparseadd(morphvec,permute(indexspace[utterance.agent.surfacestring],indefinitepermutation))\n",
    "        if (utterance.patient):\n",
    "            if (utterance.patient.definite):\n",
    "                    morphvec=sparseadd(morphvec,permute(indexspace[utterance.patient.surfacestring],definitepermutation))\n",
    "            else:\n",
    "     #       uttvec=sparseadd(uttvec,normalise(permute(comb(vectorspace[utterance.patient.surfacestring]),indefinite)))  \n",
    "                    morphvec=sparseadd(morphvec,permute(indexspace[utterance.patient.surfacestring],indefinitepermutation))\n",
    "        if (utterance.event):\n",
    "            if (utterance.event.tense==\"FUTURE\"):\n",
    "                    morphvec=sparseadd(morphvec,permute(indexspace[utterance.event.surfacestring],futuretensepermutation))\n",
    "            if (utterance.event.tense==\"PAST\"):\n",
    "                    morphvec=sparseadd(morphvec,permute(indexspace[utterance.event.surfacestring],pasttensepermutation))\n",
    "            else:\n",
    "                    morphvec=sparseadd(morphvec,permute(indexspace[utterance.event.surfacestring],presenttensepermutation))\n",
    "        uttvec=sparseadd(normalise(uttvec),normalise(morphvec))\n",
    "        if debug:\n",
    "            print(\"utterancevec() morphology: \",sparsecosine(uttvec,debugvec))\n",
    "            debugvec=uttvec\n",
    "    if semanticroles:\n",
    "        semroles = {}\n",
    "        if (utterance.patient):\n",
    "                semroles=sparseadd(semroles,permute(indexspace[utterance.patient.surfacestring],patientpermutation))\n",
    "        if (utterance.event):\n",
    "                semroles=sparseadd(semroles,permute(indexspace[utterance.event.surfacestring],eventpermutation))\n",
    "        if (utterance.event.negated):\n",
    "                semroles=sparseadd(semroles,permute(indexspace[utterance.event.surfacestring],negationpermutation))\n",
    "        if (utterance.event.adverbial):\n",
    "                semroles=sparseadd(semroles,permute(indexspace[utterance.event.adverbial],adverbialpermutation))\n",
    "        if (utterance.agent):\n",
    "                semroles=sparseadd(semroles,permute(indexspace[utterance.agent.surfacestring],agentpermutation))\n",
    "        uttvec=sparseadd(normalise(uttvec),normalise(semroles))\n",
    "        if debug:\n",
    "            print(\"utterancevec() semanticrole: \",sparsecosine(uttvec,debugvec))\n",
    "            debugvec=uttvec\n",
    "    if constructional:    # add in morphological information about the roles, no account of referent\n",
    "        constrvec={}\n",
    "        if (utterance.agent):\n",
    "            if (utterance.agent.definite):\n",
    "                constrvec=sparseadd(constrvec,permute(agentabstract,definitepermutation))\n",
    "            else:\n",
    "                constrvec=sparseadd(constrvec,permute(agentabstract,indefinitepermutation))\n",
    "        if (utterance.patient):\n",
    "            if (utterance.patient.definite):\n",
    "                constrvec=sparseadd(constrvec,permute(patientabstract,definitepermutation))\n",
    "            else:\n",
    "                constrvec=sparseadd(constrvec,permute(patientabstract,indefinitepermutation))\n",
    "        if (utterance.event):\n",
    "            if (utterance.event.tense==\"FUTURE\"):\n",
    "                constrvec=sparseadd(constrvec,permute(futureabstract,tensepermutation))\n",
    "            elif (utterance.event.tense==\"PAST\"):\n",
    "                constrvec=sparseadd(constrvec,permute(pastabstract,tensepermutation))\n",
    "            else:\n",
    "                constrvec=sparseadd(constrvec,permute(presentabstract,tensepermutation)) \n",
    "        if (utterance.event.negated):\n",
    "            uttvec=sparseadd(normalise(uttvec),normalise(permute(negationabstract,negationpermutation)))\n",
    "        uttvec=sparseadd(normalise(uttvec),normalise(constrvec))\n",
    "        if debug:\n",
    "            print(\"utterancevec() constructions: \",sparsecosine(uttvec,debugvec))\n",
    "            debugvec=uttvec\n",
    "    return uttvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initconstantsandpermutations(dimensionality=2000,densenessforabstracts=0.20):\n",
    "\n",
    "    global definitepermutation\n",
    "    global indefinitepermutation\n",
    "    global futurepermutation\n",
    "    global pasttensepermutation\n",
    "    global presenttensepermutation\n",
    "    global agentpermutation\n",
    "    global patientpermutation\n",
    "    global eventpermutation\n",
    "    global instrumentpermutation\n",
    "    global locationpermutation\n",
    "    global mannerpermutation\n",
    "    global negationpermutation\n",
    "    global adverbialpermutation\n",
    "\n",
    "    global previouspermutation\n",
    "\n",
    "    global tensepermutation\n",
    "\n",
    "    global agentabstract\n",
    "    global patientabstract\n",
    "    global eventabstract\n",
    "    global instrumentabstract\n",
    "    global locationabstract\n",
    "    global mannerabstract\n",
    "    global negationabstract\n",
    "\n",
    "    global presentabstract\n",
    "    global pastabstract\n",
    "    global progressiveabstract\n",
    "    global futureabstract\n",
    "\n",
    "    definitepermutation=createpermutation(dimensionality)\n",
    "    indefinitepermutation=createpermutation(dimensionality)\n",
    "    futurepermutation=createpermutation(dimensionality)\n",
    "    pasttensepermutation=createpermutation(dimensionality)\n",
    "    presenttensepermutation=createpermutation(dimensionality)\n",
    "    agentpermutation=createpermutation(dimensionality)\n",
    "    patientpermutation=createpermutation(dimensionality)\n",
    "    eventpermutation=createpermutation(dimensionality)\n",
    "    instrumentpermutation=createpermutation(dimensionality)\n",
    "    locationpermutation=createpermutation(dimensionality)\n",
    "    mannerpermutation=createpermutation(dimensionality)\n",
    "    negationpermutation=createpermutation(dimensionality)\n",
    "    adverbialpermutation=createpermutation(dimensionality)\n",
    "    #sequence\n",
    "    previouspermutation=createpermutation(dimensionality)\n",
    "\n",
    "    tensepermutation=createpermutation(dimensionality)\n",
    "\n",
    "    agentabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "    patientabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "    eventabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "    instrumentabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "    locationabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "    mannerabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "    negationabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "\n",
    "    presentabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "    pastabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "    progressiveabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "    futureabstract=newrandomvector(dimensionality,densenessforabstracts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_loop(debug=False,moredebug=False):\n",
    "    instring = ''\n",
    "    prev=newrandomvector(dimensionality,denseness)\n",
    "    prevlex=newrandomvector(dimensionality,denseness)\n",
    "    prevsem=newrandomvector(dimensionality,denseness)\n",
    "    prevmor=newrandomvector(dimensionality,denseness)\n",
    "    prevmgn=newrandomvector(dimensionality,denseness)\n",
    "    instring = input('> ')\n",
    "    while instring != 'quit':\n",
    "        try:\n",
    "            s = instring.rstrip()\n",
    "            wds=nltk.word_tokenize(s.lower())\n",
    "            chkwordspace(wds,debug)\n",
    "            try:\n",
    "                cs = semanticdepparse(s.lower(),debug)\n",
    "                for c in cs:\n",
    "                    u = utterancevector(c,moredebug, True, False, False,False)\n",
    "                    print(\" lexical     \",sparsecosine(prev,u),end=\"\\t(\")\n",
    "                    print(sparsecosine(prevlex,u),\")\")\n",
    "                    prevlex=u\n",
    "                    u = utterancevector(c,moredebug, False, False, True, False)\n",
    "                    print(\" semrole     \",sparsecosine(prev,u),end=\"\\t(\")\n",
    "                    print(sparsecosine(prevsem,u),\")\")\n",
    "                    prevsem=u\n",
    "                    u = utterancevector(c,moredebug,  False, True, False, False)\n",
    "                    print(\" morph     \",sparsecosine(prev,u),end=\"\\t(\")\n",
    "                    print(sparsecosine(prevmor,u),\")\")\n",
    "                    prevmor=u\n",
    "                    u = utterancevector(c,moredebug, False, False, False, True)\n",
    "                    print(\" construction  \",sparsecosine(prev,u),end=\"\\t(\")\n",
    "                    print(sparsecosine(prevmgn,u),\")\")\n",
    "                    prevmgn=u\n",
    "                    u = utterancevector(c,moredebug)\n",
    "                    print(\" in toto     \",sparsecosine(prev,u))\n",
    "                    prev = u\n",
    "            except:\n",
    "                print(\"****\")\n",
    "            instring = input('> ')\n",
    "        except:\n",
    "            instring = 'quit'\n",
    "    print(\"hey!\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "command_loop(False,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pastabstract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-47a626b2eb9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The fish ate the worm.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"she winked.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpastabstract\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtensepermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msemanticdepparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mbp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msemanticdepparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pastabstract' is not defined"
     ]
    }
   ],
   "source": [
    "# lexicon: what concepts are mentioned (context vectors)\n",
    "f1 = False\n",
    "\n",
    "# morphology: what morphological form is represented (index vectors permuted with morph permutations)\n",
    "f2 = True\n",
    "\n",
    "# semantic roles: e.g. is the agent definite? (index vectors, deep case permutations)\n",
    "f3 = True\n",
    "\n",
    "# constructions: (abstract random feature vectors)\n",
    "f4 = True\n",
    "\n",
    "#debug output (no good at present)\n",
    "d = False\n",
    "a = \"The cat eats the cream.\"\n",
    "b = \"The fish ate the worm.\"\n",
    "c = \"she winked.\"\n",
    "target=permute(pastabstract,tensepermutation)\n",
    "ap = semanticdepparse(a.lower())[0]\n",
    "bp = semanticdepparse(b.lower())[0]\n",
    "cp = semanticdepparse(c.lower())[0]\n",
    "av = utterancevector(ap,d,f1,f2,f3,f4)\n",
    "bv = utterancevector(bp,d,f1,f2,f3,f4)\n",
    "cv = utterancevector(cp,d,f1,f2,f3,f4)\n",
    "\n",
    "print(\"a vs b\\t\",sparsecosine(av,bv))\n",
    "print(\"a vs c\\t\",sparsecosine(av,cv))\n",
    "print(\"b vs c\\t\",sparsecosine(bv,cv))\n",
    "\n",
    "print(\"a vs tgt\\t\",sparsecosine(av,target))\n",
    "print(\"b vs tgt\\t\",sparsecosine(bv,target))\n",
    "print(\"c vs tgt\\t\",sparsecosine(cv,target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.event.tense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initunittest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test negation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how soon will a vector be saturated?\n",
    "results: the densensess of the vector has no bearing on the quality of the retrieval. i have tested here with denseness stepped from 0.1 to 1 of a randomised abstract vector. all come out with same retrieval cosine. but the cosine varies for different tasks. need to check why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "initconstantsandpermutations(dimensionality,0.2)\n",
    "indexspace={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "definite:\t 0.3973\n",
      "definite:\t 0.4102\n",
      "negation:\t 0.6985\n",
      "non-neg vs negation:\t -0.0241\n",
      "present:\t 0.5793\n",
      "past vs present:\t 0.0323\n",
      "neg vs non-neg:\t 0.4826\n",
      "similar lex:\t 1.0\n",
      "similar lex:\t 0.6808\n"
     ]
    }
   ],
   "source": [
    "#for denseness in [0.05]: #[0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01]:\n",
    "\n",
    "\n",
    "#for k in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]:\n",
    "#    negationabstract=newrandomvector(dimensionality,k)\n",
    "#    presentabstract=newrandomvector(dimensionality,k)\n",
    "\n",
    "def uv(words):\n",
    "    utterance=semanticdepparse(words.lower())[0]\n",
    "    return utterancevector(utterance,False, False, True, True, True)\n",
    "\n",
    "\n",
    "print(\"definite:\\t\",sparsecosine(uv(\"The cat does not eat the fish.\"),permute(agentabstract,definitepermutation)))\n",
    "print(\"definite:\\t\",sparsecosine(uv(\"The cat does not eat the fish.\"),permute(patientabstract,definitepermutation)))\n",
    "print(\"negation:\\t\",sparsecosine(uv(\"The cat does not eat the fish.\"),permute(negationabstract,negationpermutation)))\n",
    "print(\"non-neg vs negation:\\t\",sparsecosine(uv(\"The cat eats the fish.\"),permute(negationabstract,negationpermutation)))\n",
    "print(\"present:\\t\",sparsecosine(uv(\"The cat eats the fish.\"),permute(presentabstract,tensepermutation)))\n",
    "print(\"past vs present:\\t\",sparsecosine(uv(\"The cat has not eaten the fish.\"),permute(presentabstract,tensepermutation)))\n",
    "print(\"neg vs non-neg:\\t\",sparsecosine(uv(\"The cat eats the fish.\"),uv(\"The cat did not eat the fish.\")))\n",
    "print(\"similar lex:\\t\",sparsecosine(uv(\"The cat eats the fish.\"),uv(\"The dog eats the fish.\")))\n",
    "print(\"similar lex:\\t\",sparsecosine(uv(\"The cat eats the fish.\"),uv(\"The fish ate the worm.\")))\n",
    "\n",
    "#initconstantsandpermutations(dimensionality,0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we find indefinite agents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in utterancespace:\n",
    "    c = sparsecosine(utterancespace[i],vectorspace[\"hand\"])  #sparseadd(,normalise(permute(negationabstract,negationpermutation)))) #sparseadd(permute(negationabstract,negationpermutation),permute(agentabstract,definitepermutation)))) #,permute(negationabstract,negationpermutation)))\n",
    "    if (c > 0.1):\n",
    "        d = sparsecosine(utterancespace[i],permute(negationabstract,negationpermutation))\n",
    "        print (c, d,i)\n",
    "        if (d > 0.1):\n",
    "            print (c, d,i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weighting\n",
    "\n",
    "now an exponential, math.exp(200*math.pi*bign/globalfrequency(wd)) which defaults to 0.5 if unknown word, i'd prefer arc tan tho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two new spaces, using known context vectors, one weighted one not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspace = {}\n",
    "newweightedspace = {}\n",
    "target = \"victor\"\n",
    "for uu in utterancespace:\n",
    "    wds=nltk.word_tokenize(uu.lower())\n",
    "    if target in wds:\n",
    "        newtestvector = {}\n",
    "        newweightedtestvector = {}\n",
    "        for wd in wds:\n",
    "            try:\n",
    "                n1 = newtestvector\n",
    "                newtestvector = sparseadd(newtestvector,normalise(comb(vectorspace[wd])),1,False)\n",
    "                print(wd,\" \",wds,\" \",sparsecosine(n1,newtestvector))\n",
    "                newweightedtestvector = sparseadd(newweightedtestvector,normalise(comb(vectorspace[wd])),frequencyweight(wd),False)\n",
    "            except KeyError:\n",
    "                pass\n",
    "        newspace[uu] = newtestvector\n",
    "        newweightedspace[uu] = newweightedtestvector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the new space, for each word in an utterance, how close is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probewd = \"victor\"\n",
    "\n",
    "for uu in newspace:\n",
    "    wds=nltk.word_tokenize(uu.lower())\n",
    "    print(\"============================\")\n",
    "    print(uu)\n",
    "    if probewd in wds:\n",
    "        for wd in wds:\n",
    "            try:\n",
    "                cc = sparsecosine(newspace[uu],comb(vectorspace[wd]))\n",
    "                ccw = sparsecosine(newweightedspace[uu],comb(vectorspace[wd]))\n",
    "                print(cc,\"\\t\",ccw,\"\\t\",wd,\"\\t\",round(frequencyweight(wd),2),\"\\t\",uu)\n",
    "            except KeyError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_grep(debug=False,moredebug=False):\n",
    "    instring = ''\n",
    "    instring = input('> ')\n",
    "    prev=newrandomvector(dimensionality,denseness)\n",
    "    prevstring = \"null\"\n",
    "    ryggrad=permute(negationabstract,negationpermutation)\n",
    "    while instring != 'quit':\n",
    "        try:\n",
    "            s = instring.rstrip()\n",
    "            wds=nltk.word_tokenize(s.lower())\n",
    "            chkwordspace(wds,debug)\n",
    "            try:\n",
    "                cs = semanticdepparse(s.lower(),debug)\n",
    "                for c in cs:\n",
    "                    u = utterancevector(c,moredebug)\n",
    "                    print(\" cosine between \",wds,\" and \",prevstring,\" :     \",sparsecosine(prev,u))\n",
    "                    print(\" cosine between \",wds,\" and negation :     \",sparsecosine(ryggrad,u))\n",
    "                    prev = u\n",
    "                    prevstring = wds\n",
    "            except:\n",
    "                print(\"****\")\n",
    "            instring = input('> ')\n",
    "        except:\n",
    "            instring = 'quit'\n",
    "    print(\"hey!\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparserecoverabilityexperiment():\n",
    "    step = 20\n",
    "    start = 10\n",
    "    stop = 150\n",
    "    acceptable = 0.2\n",
    "    for cellsize in [2,3,4,9,16,25,36,64,100]:\n",
    "        print(\"=============================================\")\n",
    "        print(\"number of features aggregated: \",cellsize)\n",
    "        print(\"analytic optimum: \",(2*cellsize*dimensionality)**(-1/3)*dimensionality)\n",
    "\n",
    "        #cellsize = 9 # how many features in an utterance (includes words)\n",
    "        d = start\n",
    "        featspace = {} # a hash of cellsize random vectors of denseness d\n",
    "        featvec = {} # an addition of cellsize random vectors of denseness d into one vector\n",
    "        bigs = 0\n",
    "        ii = 0\n",
    "        while (d <= stop):\n",
    "            i = 0\n",
    "            featspace[d] = [None]*cellsize\n",
    "            featvec[d] = {}\n",
    "            while (i < cellsize): \n",
    "                featspace[d][i] = newrandomvector(dimensionality,d / dimensionality)\n",
    "                prev = featvec[d]\n",
    "                featvec[d] = sparseadd(featvec[d],featspace[d][i])\n",
    "#            print(d,i,sparsecosine(prev,featvec[d]),sparsecosine(featvec[d],featspace[d][i]),sep=\"\\t\")\n",
    "                i += 1\n",
    "            i = 0\n",
    "            lils = 0\n",
    "            #esses = 0\n",
    "            while (i < cellsize):\n",
    "                c = sparsecosine(featvec[d],featspace[d][i])\n",
    "#            print(d,i,sparselength(featspace[d][i]),sep=\"\\t\")\n",
    "            #if c < acceptable:\n",
    "            #    esses += 1\n",
    "                lils += c\n",
    "                i += 1\n",
    "            avs = lils / cellsize\n",
    "#        print(d,i,sparselength(featvec[d]),sep=\"\\t\")\n",
    "            print(d,end=\"\\t\", flush=True)\n",
    "#        print(\"\\tfeature: \",\"{0:.3f}\".format(avs),\" (\",esses,\")\", flush=True)\n",
    "            print(\"\\tfeature: \",\"{0:.3f}\".format(avs), flush=True)\n",
    "            ii += i\n",
    "            bigs += lils\n",
    "            d += step\n",
    "        avs = bigs / ii\n",
    "        print(\"average retrievability: \",\"{0:.4f}\".format(avs))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparserecoverabilityexperiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
