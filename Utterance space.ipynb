{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparseadd(onevec,othvec,weight=1):\n",
    "    result={}\n",
    "    try:\n",
    "        for l in onevec:\n",
    "            result[l] = onevec[l]\n",
    "        for k in othvec:\n",
    "            if k in result:\n",
    "                result[k] = result[k]+othvec[k]*float(weight)\n",
    "            else:\n",
    "                result[k] = othvec[k]*float(weight)\n",
    "    except:\n",
    "        print(\"sparseadd(): error\")\n",
    "    return result\n",
    "def sparsemultiply(onevec,othvec,weight=1):\n",
    "    result={}\n",
    "    try:\n",
    "        for l in onevec:\n",
    "            if l in othvec:\n",
    "                result[l] = onevec[l]*othvec[l]*float(weight)\n",
    "    except:\n",
    "        print(\"sparsemultiply(): error \")\n",
    "    return result\n",
    "def sparsexor(onevec,othvec):\n",
    "    result={}\n",
    "    try:\n",
    "        for l in range(len(onevec)):\n",
    "            if ((l in onevec) and not (l in othvec)):\n",
    "                result[l] = 1\n",
    "            if (not (l in onevec) and (l in othvec)):\n",
    "                result[l] = 1        \n",
    "    except:\n",
    "        print(\"sparsexor(): error \")\n",
    "    return result\n",
    "\n",
    "def newrandomvector(n,k):\n",
    "    vec = {}\n",
    "    if (k > 0):# no need to be careful about this, right? and k % 2 == 0):\n",
    "        nonzeros = random.sample(list(range(n)),k)\n",
    "        negatives = random.sample(nonzeros,k//2)\n",
    "        for i in nonzeros:\n",
    "            vec[str(i)] = 1;\n",
    "        for i in negatives:\n",
    "            vec[str(i)] = -1;\n",
    "    return vec\n",
    "\n",
    "def newoperator(n):\n",
    "    k = n//10\n",
    "    return newrandomvector(n,k)\n",
    "\n",
    "def sparsecosine(xvec,yvec,truncate=True):\n",
    "    x2 = 0;\n",
    "    y2 = 0;\n",
    "    xy = 0;\n",
    "    try:\n",
    "        for i in xvec:\n",
    "            x2 = x2+xvec[i]*xvec[i]\n",
    "    except:\n",
    "        print(\"sparsecosine(): error at position \",i)\n",
    "    try:\n",
    "        for j in yvec:\n",
    "            y2 = y2+yvec[j]*yvec[j]\n",
    "            if j in xvec:\n",
    "                xy = xy+xvec[j]*yvec[j]\n",
    "    except:\n",
    "        print(\"sparsecosine(): errors at position \",j)\n",
    "    if (x2*y2 == 0):\n",
    "        cos = 0\n",
    "    else:\n",
    "        cos = xy/(math.sqrt(x2)*math.sqrt(y2))\n",
    "    if (truncate):\n",
    "        cos=int(cos*10000)/10000\n",
    "    return cos\n",
    "\n",
    "def sparselength(vec,truncate=True):\n",
    "    x2 = 0\n",
    "    length=0\n",
    "    try:\n",
    "        for i in vec:\n",
    "            x2 = x2+vec[i]*vec[i]\n",
    "    except:\n",
    "        print(\"sparselength(): error at position \",i)\n",
    "    if (x2 > 0):\n",
    "        length = math.sqrt(x2)\n",
    "    if (truncate):\n",
    "        length=int(length*10000)/10000\n",
    "    return length\n",
    "\n",
    "def comb(vec,k=0.1):\n",
    "    newvector={}\n",
    "    n=int(k*dimensionality/2)\n",
    "    sorted_items=sorted(vec.items(), key=lambda x:x[1])\n",
    "    bot=sorted_items[:n]\n",
    "    top=sorted_items[-n:]\n",
    "    for l in bot:\n",
    "        newvector[l[0]]=l[1]\n",
    "    for l in top:\n",
    "        newvector[l[0]]=l[1]\n",
    "    return newvector\n",
    "\n",
    "def sparsesum(vec):\n",
    "    s=0\n",
    "    for i in vec:\n",
    "        s += float(vec[i])\n",
    "    return s\n",
    "\n",
    "def normalise(vec,truncate=True):\n",
    "    newvector={}\n",
    "    vlen=sparselength(vec,False)\n",
    "    if (vlen > 0):\n",
    "        for i in vec:\n",
    "            newvector[i]=vec[i]/math.sqrt(vlen*vlen)\n",
    "    else:\n",
    "        newvector=vec\n",
    "    return newvector\n",
    "\n",
    "def modify(vec,factor):\n",
    "    newvector={}\n",
    "    for i in vec:\n",
    "        if (random.random() > factor):\n",
    "            newvector[i]=vec[i]\n",
    "        else:\n",
    "            newvector[i]=float(vec[i])*(0.5-random.random())*2.0\n",
    "    return newvector\n",
    "\n",
    "def createpermutation(k):\n",
    "    permutation=random.sample(range(k), k)\n",
    "    return permutation\n",
    "    \n",
    "def permute(vector,permutation):\n",
    "    newvector={}\n",
    "    try:\n",
    "        for i in range(len(permutation)):\n",
    "            if str(i) in vector:\n",
    "                newvector[str(permutation[i])]=vector[str(i)]\n",
    "    except:\n",
    "        newvector=vector\n",
    "        print(\"permute(): no permutation done, something wrong\")\n",
    "    return newvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordspacefile=\"/home/jussi/Desktop/data/wordspaces/gavagai-news-22-morethan5.wordspace\"\n",
    "dimensionality=2000\n",
    "denseness=10\n",
    "fdgtextfile=\"/home/jussi/Desktop/data/GH95-fdg/950102.sgml.fdg.xml\"\n",
    "unittestfile=\"/home/jussi/Desktop/data/cooksents.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "definitepermutation=createpermutation(dimensionality)\n",
    "indefinitepermutation=createpermutation(dimensionality)\n",
    "futurepermutation=createpermutation(dimensionality)\n",
    "pasttensepermutation=createpermutation(dimensionality)\n",
    "presenttensepermutation=createpermutation(dimensionality)\n",
    "agentpermutation=createpermutation(dimensionality)\n",
    "patientpermutation=createpermutation(dimensionality)\n",
    "eventpermutation=createpermutation(dimensionality)\n",
    "instrumentpermutation=createpermutation(dimensionality)\n",
    "locationpermutation=createpermutation(dimensionality)\n",
    "mannerpermutation=createpermutation(dimensionality)\n",
    "negationpermutation=createpermutation(dimensionality)\n",
    "adverbialpermutation=createpermutation(dimensionality)\n",
    "\n",
    "densenessforabstracts=dimensionality//10\n",
    "agentabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "patientabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "eventabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "instrumentabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "locationabstract=newrandomvector(dimensionality,densenessforabstracts)\n",
    "mannerabstract=newrandomvector(dimensionality,densenessforabstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class clause:\n",
    "    cleanuppattern=re.compile(r'[\\.\\'\\!\\*\\?\\+,;\\:\\-\\/]+')\n",
    "    def __init__(self,string):\n",
    "        self.surfacestring=string\n",
    "        self.cleanedutterance=re.sub(clause.cleanuppattern,\"\",string)\n",
    "        self.tokens=self.cleanedutterance.lower().split()\n",
    "        self.agent=None\n",
    "        self.event=None\n",
    "        self.patient=None\n",
    "        self.instrument=None\n",
    "        self.location=None\n",
    "        self.manner=None\n",
    "    def __str__(self):\n",
    "        return self.surfacestring\n",
    "    \n",
    "class referent:\n",
    "    def __init__(self, string):\n",
    "        self.surfacestring=string\n",
    "        self.definite=True\n",
    "        self.number=1\n",
    "        \n",
    "class event:\n",
    "    def __init__(self, string):\n",
    "        self.surfacestring=string    \n",
    "        self.negated=False    \n",
    "        self.adverbial=None    \n",
    "        self.tense=None #past present or future\n",
    "        self.aspect=None #ongoing perfect or pointwise\n",
    "        self.mood=None #indicative, irreal, potential, optative, not, imperative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "path_to_stanford_corenlp = '/usr/share/stanford-corenlp-full/'\n",
    "parser_jar='stanford-corenlp.jar'\n",
    "path_to_models = path_to_stanford_corenlp+'models/'\n",
    "model_jar='stanford-english-corenlp-models.jar'\n",
    "dependency_parser = StanfordDependencyParser(path_to_jar=path_to_stanford_corenlp+parser_jar, path_to_models_jar=path_to_models+model_jar)\n",
    "\n",
    "def semanticdepparse(string,debug=False):\n",
    "    utterance=clause(string)\n",
    "    utterance.agent=referent(\"epsilon\")\n",
    "    utterance.patient=referent(\"epsilon\")\n",
    "    utterance.event=event(\"epsilon\")\n",
    "    depgraph=dependency_parser.raw_parse(string)\n",
    "    scratch={}\n",
    "    negated=False\n",
    "    adverbial=None\n",
    "    for deps in depgraph:\n",
    "#        if debug:\n",
    "#            print(deps)\n",
    "        for nodeindex in deps.nodes:\n",
    "            if deps.nodes[nodeindex]['rel'] == 'neg':\n",
    "                negated=True\n",
    "            elif deps.nodes[nodeindex]['rel'] == 'advmod':\n",
    "                adverbial=deps.nodes[nodeindex]['word']\n",
    "            elif deps.nodes[nodeindex]['rel'] == 'nsubj':\n",
    "                utterance.agent=referent(deps.nodes[nodeindex]['word'])\n",
    "                if nodeindex in scratch: \n",
    "                    if scratch[nodeindex]==\"def\":\n",
    "                        utterance.agent.definite=True\n",
    "                    elif scratch[nodeindex]==\"indef\":\n",
    "                        utterance.agent.definite=False\n",
    "            elif deps.nodes[nodeindex]['rel'] == 'nmod:poss':\n",
    "                scratch[deps.nodes[nodeindex]['head']]=\"def\"\n",
    "            elif deps.nodes[nodeindex]['rel'] == 'det':\n",
    "                if (deps.nodes[nodeindex]['word']==\"a\" or deps.nodes[nodeindex]['word']==\"an\"):\n",
    "                    scratch[deps.nodes[nodeindex]['head']]=\"indef\"\n",
    "                elif (deps.nodes[nodeindex]['word']==\"the\"):\n",
    "                    scratch[deps.nodes[nodeindex]['head']]=\"def\"\n",
    "            elif deps.nodes[nodeindex]['rel'] == 'root':\n",
    "                utterance.event=event(deps.nodes[nodeindex]['word'])\n",
    "            elif deps.nodes[nodeindex]['rel'] == 'dobj':\n",
    "                utterance.patient=referent(deps.nodes[nodeindex]['word'])\n",
    "                if nodeindex in scratch: \n",
    "                    if scratch[nodeindex]==\"def\":\n",
    "                        utterance.patient.definite=True\n",
    "                    elif scratch[nodeindex]==\"indef\":\n",
    "                        utterance.patient.definite=False\n",
    "        try:\n",
    "            utterance.event.negated=negated\n",
    "        except:\n",
    "            print(\"semanticdepparse(): negation mismatch in \"+string)\n",
    "        try:\n",
    "            utterance.event.adverbial=adverbial\n",
    "        except:\n",
    "            print(\"semanticdepparse(): adverbial blowout in \"+string)\n",
    "    if debug:\n",
    "            print(\"semanticdepparse(): e:\",utterance.event.surfacestring,\" a:\",utterance.agent.surfacestring,\" p:\",utterance.patient.surfacestring)\n",
    "    return utterance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chkwordspace():  epsilon  is new and is now hallucinated.\n"
     ]
    }
   ],
   "source": [
    "vectorspace={}\n",
    "globalfrequency={}\n",
    "indexspace={}\n",
    "associationspace={}\n",
    "\n",
    "def chkwordspace(words,debug=False):\n",
    "    i = 0\n",
    "    for w in words:\n",
    "        if w in vectorspace:\n",
    "                i += 1\n",
    "        else:\n",
    "            if debug:\n",
    "                print(\"chkwordspace(): \",w,\" is new and is now hallucinated.\")\n",
    "            denseness2=dimensionality//2\n",
    "            vectorspace[w] = newrandomvector(dimensionality,denseness2)\n",
    "            indexspace[w] = newrandomvector(dimensionality,denseness)\n",
    "            associationspace[w] = newrandomvector(dimensionality,denseness2)    \n",
    "\n",
    "chkwordspace([\"epsilon\"],True)\n",
    "\n",
    "def wordlikeness(w1,w2):\n",
    "    return sparsecosine(vectorspace[w1],vectorspace[w2])\n",
    "\n",
    "def dowordspacefile(wordspacefile):\n",
    "    linepattern = re.compile(r'^\\(\\\"([\\-\\w]+)\\\"\\s+#S2000([\\d\\,\\-\\.\\-\\+;e]+)*:\\s+#S2000([\\d\\-\\+;\\.e\\,]+)*:\\s+#S2000([\\.\\d\\-\\+;e\\,]+)*:\\s+(\\d+)\\)')\n",
    "    vecpattern = re.compile(r';?(\\d+)([\\+\\-][\\,\\.\\d]+(e-\\d\\d)?)')\n",
    "    alicefile=open(wordspacefile,'r')\n",
    "    global vectorspace\n",
    "    vectorspace={}\n",
    "    global globalfrequency\n",
    "    globalfrequency={}\n",
    "    global indexspace\n",
    "    indexspace={}\n",
    "    global associationspace\n",
    "    associationspace={}\n",
    "    aliceline = alicefile.readline()\n",
    "    a=1\n",
    "    b=0\n",
    "    w=0\n",
    "    while aliceline:\n",
    "        a = a+1\n",
    "        m=linepattern.match(aliceline)\n",
    "        if m:\n",
    "            token=m.groups()[0]\n",
    "            ind=m.groups()[1]\n",
    "            doc=m.groups()[2]\n",
    "            ctx=m.groups()[3]\n",
    "            freq=int(m.groups()[4])\n",
    "#            if (filtering and token )\n",
    "            try:\n",
    "                sparsevec={}\n",
    "                cells = re.findall(vecpattern,ctx)\n",
    "                for c in cells:\n",
    "                    val = c[1]\n",
    "                    kop=val.translate(str.maketrans(\",\",\".\",\"+\"))\n",
    "                    try:\n",
    "                        sparsevec[c[0]] = float(kop)\n",
    "                    except:\n",
    "                        print(\"weird number: \",kop)\n",
    "                vectorspace[token] = sparsevec\n",
    "                sparsevec={}\n",
    "                cells = re.findall(vecpattern,ind)\n",
    "                for c in cells:\n",
    "                    val = c[1]\n",
    "                    kop=val.translate(str.maketrans(\",\",\".\",\"+\"))\n",
    "                    try:\n",
    "                        sparsevec[c[0]] = float(kop)\n",
    "                    except:\n",
    "                        print(\"weird number: \",kop)\n",
    "                indexspace[token] = sparsevec\n",
    "                globalfrequency[token] = freq\n",
    "                sparsevec={}\n",
    "                w=w+1\n",
    "            except:\n",
    "                print(\"fail: \",token,\" \",a)\n",
    "        else:\n",
    "            b=b+1\n",
    "        aliceline = alicefile.readline()\n",
    "    print(a,\" lines seen; \",w,\" items added \",b,\" items disregarded\")\n",
    "    alicefile.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utterancevector(utterance,debug=False,normalised=True,lexical=True,morphology=True,semanticroles=True,morphologyrole=True):\n",
    "    baremorphology=morphology\n",
    "    combinedmorphology=lexical\n",
    "    uttvec={}\n",
    "    if debug:\n",
    "        debugvec={}\n",
    "    if lexical:     # add in referent, using its context vector meaning more or less the concept it refers to\n",
    "        if (utterance.patient):\n",
    "            if normalised:\n",
    "                uttvec=sparseadd(\n",
    "                    uttvec,\n",
    "                    normalise(\n",
    "                        comb(\n",
    "                            vectorspace[utterance.patient.surfacestring])))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,comb(vectorspace[utterance.patient.surfacestring]))\n",
    "        if (utterance.event):\n",
    "            if normalised:\n",
    "                uttvec=sparseadd(uttvec,normalise(comb(vectorspace[utterance.event.surfacestring])))#,sparselength(vectorspace[utterance.verb]))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,comb(vectorspace[utterance.patient.surfacestring]))\n",
    "        if (utterance.agent):\n",
    "            if normalised:\n",
    "                uttvec=sparseadd(uttvec,normalise(comb(vectorspace[utterance.agent.surfacestring])))#,sparselength(vectorspace[utterance.agent]))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,comb(vectorspace[utterance.agent.surfacestring]))\n",
    "    if debug:\n",
    "        print(\"utterancevec() lexicon: \",sparsecosine(uttvec,debugvec))\n",
    "        debugvec=uttvec\n",
    "    if morphology:     # add in morphological information about the roles of the referent\n",
    "        if (utterance.agent):\n",
    "            if (utterance.agent.definite):\n",
    "                if normalised:\n",
    "                    uttvec=sparseadd(\n",
    "                        uttvec,\n",
    "                        normalise(\n",
    "                            permute(\n",
    "                                indexspace[utterance.agent.surfacestring],\n",
    "                                definitepermutation)))\n",
    "                else:\n",
    "                    uttvec=sparseadd(uttvec,permute(indexspace[utterance.agent.surfacestring],definitepermutation))\n",
    "            else:\n",
    "                if normalised:\n",
    "                    uttvec=sparseadd(uttvec,normalise(permute(indexspace[utterance.agent.surfacestring],indefinitepermutation)))\n",
    "                else:\n",
    "                    uttvec=sparseadd(uttvec,permute(indexspace[utterance.agent.surfacestring],indefinitepermutation))\n",
    "        if (utterance.patient):\n",
    "            if (utterance.patient.definite):\n",
    "                if normalised:\n",
    "                    uttvec=sparseadd(\n",
    "                        uttvec,\n",
    "                        normalise(\n",
    "                            permute(indexspace[utterance.patient.surfacestring],\n",
    "                                    definitepermutation)))\n",
    "                else:\n",
    "                    uttvec=sparseadd(uttvec,permute(indexspace[utterance.patient.surfacestring],definitepermutation))\n",
    "            else:\n",
    "     #       uttvec=sparseadd(uttvec,normalise(permute(comb(vectorspace[utterance.patient.surfacestring]),indefinite)))  \n",
    "                if normalised:\n",
    "                    uttvec=sparseadd(uttvec,normalise(permute(indexspace[utterance.patient.surfacestring],indefinitepermutation)))\n",
    "                else:\n",
    "                    uttvec=sparseadd(uttvec,permute(indexspace[utterance.patient.surfacestring],indefinitepermutation))\n",
    "        if (utterance.event):\n",
    "            if (utterance.event.tense==\"FUTURE\"):\n",
    "                if normalised:\n",
    "                    uttvec=sparseadd(uttvec,normalise(permute(vectorspace[utterance.event.surfacestring],futuretensepermutation)))\n",
    "                else:\n",
    "                    uttvec=sparseadd(uttvec,permute(vectorspace[utterance.event.surfacestring],futuretensepermutation))\n",
    "            else:\n",
    "                if normalised:\n",
    "                    uttvec=sparseadd(uttvec,normalise(permute(vectorspace[utterance.event.surfacestring],presenttensepermutation)) )  \n",
    "                else:\n",
    "                    uttvec=sparseadd(uttvec,permute(vectorspace[utterance.event.surfacestring],presenttensepermutation))\n",
    "    if debug:\n",
    "        print(\"utterancevec() morphology: \",sparsecosine(uttvec,debugvec))\n",
    "        debugvec=uttvec\n",
    "    if morphologyrole:    # add in morphological information about the roles, no account of referent\n",
    "        if (utterance.agent):\n",
    "            if (utterance.agent.definite):\n",
    "                uttvec=sparseadd(uttvec,normalise(permute(agentabstract,definitepermutation)))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,normalise(permute(agentabstract,indefinitepermutation)))\n",
    "        if (utterance.patient):\n",
    "            if (utterance.patient.definite):\n",
    "                uttvec=sparseadd(uttvec,normalise(permute(patientabstract,definitepermutation)))\n",
    "            else:\n",
    "                 uttvec=sparseadd(uttvec,normalise(permute(patientabstract,indefinitepermutation)))\n",
    "        if (utterance.event):\n",
    "            if (utterance.event.tense==\"FUTURE\"):\n",
    "                uttvec=sparseadd(uttvec,normalise(permute(eventabstract,futuretensepermutation)))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,normalise(permute(eventabstract,presenttensepermutation)) )  \n",
    "    if debug:\n",
    "        print(\"utterancevec() morphologyrole: \",sparsecosine(uttvec,debugvec))\n",
    "        debugvec=uttvec\n",
    "    if semanticroles:\n",
    "        if (utterance.patient):\n",
    "            if normalised:\n",
    "                uttvec=sparseadd(uttvec,permute(normalise(indexspace[utterance.patient.surfacestring]),patientpermutation))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,permute(indexspace[utterance.patient.surfacestring],patientpermutation))\n",
    "        if (utterance.event):\n",
    "            if normalised:\n",
    "                uttvec=sparseadd(uttvec,permute(normalise(indexspace[utterance.event.surfacestring]),eventpermutation))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,permute(indexspace[utterance.event.surfacestring],eventpermutation))\n",
    "        if (utterance.event.negated):\n",
    "            if normalised:\n",
    "                uttvec=sparseadd(uttvec,permute(normalise(indexspace[utterance.event.surfacestring]),negationpermutation))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,permute(indexspace[utterance.event.surfacestring],negationpermutation))\n",
    "        if (utterance.event.adverbial):\n",
    "            if normalised:\n",
    "                uttvec=sparseadd(uttvec,permute(normalise(indexspace[utterance.event.adverbial]),adverbialpermutation))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,permute(indexspace[utterance.event.adverbial],adverbialpermutation))\n",
    "        if (utterance.agent):\n",
    "            if normalised:\n",
    "                uttvec=sparseadd(uttvec,permute(normalise(indexspace[utterance.agent.surfacestring]),agentpermutation))\n",
    "            else:\n",
    "                uttvec=sparseadd(uttvec,permute(indexspace[utterance.agent.surfacestring],agentpermutation))\n",
    "    if debug:\n",
    "        print(\"utterancevec() semanticrole: \",sparsecosine(uttvec,debugvec))\n",
    "        debugvec=uttvec\n",
    "    return uttvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail:  848-4158   251\n",
      "fail:  j3   1843\n",
      "fail:  939-3090   5604\n",
      "fail:  artefax   5692\n",
      "fail:  259-0033   5979\n",
      "fail:  409-8008   6611\n",
      "fail:  789-3456   12498\n",
      "fail:  thwang   14318\n",
      "fail:  30-oct   14713\n",
      "fail:  938-9828   14879\n",
      "fail:  259-7800   18300\n",
      "fail:  840-6118   25485\n",
      "fail:  650-5112   25870\n",
      "fail:  laserbits   26632\n",
      "fail:  492-0465   27336\n",
      "fail:  885-4900   27849\n",
      "fail:  871-1052   29176\n",
      "fail:  273-7000   34112\n",
      "fail:  885-5348   34937\n",
      "fail:  725-0300   35289\n",
      "fail:  727-1648   36388\n",
      "fail:  375-1000   38233\n",
      "fail:  365-8086   38337\n",
      "fail:  834-1485   39746\n",
      "fail:  lany   48235\n",
      "fail:  chv   54315\n",
      "fail:  kph   77436\n",
      "fail:  ochone   94206\n",
      "fail:  4269   101773\n",
      "fail:  01267   102457\n",
      "fail:  -1230   102881\n",
      "fail:  -430   109265\n",
      "fail:  8504   112260\n",
      "fail:  -530   112513\n",
      "fail:  attys   112964\n",
      "fail:  76696   117710\n",
      "fail:  bedrms   119252\n",
      "fail:  videobits   123916\n",
      "138847  lines seen;  135758  items added  3050  items disregarded\n"
     ]
    }
   ],
   "source": [
    "dowordspacefile(wordspacefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterancespace = {}\n",
    "dependencyanalysisstore={}\n",
    "def initunittest(debug=False):\n",
    "    with open(unittestfile,\"r\") as sents:\n",
    "        s = sents.readline().rstrip()\n",
    "        i = 0\n",
    "        while s:\n",
    "            print(s)\n",
    "            wds=nltk.word_tokenize(s.lower())\n",
    "            chkwordspace(wds,debug)\n",
    "            try:\n",
    "                c = semanticdepparse(s.lower(),debug)\n",
    "                dependencyanalysisstore[s]=c\n",
    "                u = utterancevector(c,debug)\n",
    "                utterancespace[s] = u\n",
    "                i += 1\n",
    "            except:\n",
    "                print(\"****\",s)\n",
    "            s = sents.readline()\n",
    "def rununittest():\n",
    "    for v in utterancespace:\n",
    "        print(v)\n",
    "        for w in utterancespace:\n",
    "            print(\"          \",sparsecosine(utterancespace[v],utterancespace[w]),\" \",w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cook makes a pie.\n",
      "semanticdepparse(): e: makes  a: cook  p: pie\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7076\n",
      "utterancevec() morphologyrole:  1.0\n",
      "utterancevec() syntacticrole:  0.8182\n",
      "A cook bakes a pie.\n",
      "\n",
      "semanticdepparse(): e: bakes  a: cook  p: pie\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.6837\n",
      "utterancevec() morphologyrole:  0.9999\n",
      "utterancevec() syntacticrole:  0.8231\n",
      "The cook bakes the cake.\n",
      "\n",
      "semanticdepparse(): e: bakes  a: cook  p: cake\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7017\n",
      "utterancevec() morphologyrole:  1.0\n",
      "utterancevec() syntacticrole:  0.8232\n",
      "The cook makes the stew.\n",
      "\n",
      "semanticdepparse(): e: makes  a: cook  p: stew\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7158\n",
      "utterancevec() morphologyrole:  1.0\n",
      "utterancevec() syntacticrole:  0.8207\n",
      "The cook prepared fish.\n",
      "\n",
      "semanticdepparse(): e: prepared  a: cook  p: fish\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7286\n",
      "utterancevec() morphologyrole:  1.0\n",
      "utterancevec() syntacticrole:  0.8336\n",
      "The cook prepared the fish.\n",
      "\n",
      "semanticdepparse(): e: prepared  a: cook  p: fish\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7286\n",
      "utterancevec() morphologyrole:  1.0\n",
      "utterancevec() syntacticrole:  0.8336\n",
      "The cook prepared a fish.\n",
      "\n",
      "semanticdepparse(): e: prepared  a: cook  p: fish\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7364\n",
      "utterancevec() morphologyrole:  1.0\n",
      "utterancevec() syntacticrole:  0.8346\n",
      "The cook does not bake a pie.\n",
      "\n",
      "semanticdepparse(): e: bake  a: cook  p: pie\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7039\n",
      "utterancevec() morphologyrole:  1.0\n",
      "utterancevec() syntacticrole:  0.7798\n",
      "The cook probably bakes a pie.\n",
      "\n",
      "semanticdepparse(): e: bakes  a: cook  p: pie\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.6946\n",
      "utterancevec() morphologyrole:  1.0\n",
      "utterancevec() syntacticrole:  0.7837\n",
      "The cook does not prepare a fish.\n",
      "\n",
      "semanticdepparse(): e: prepare  a: cook  p: fish\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7477\n",
      "utterancevec() morphologyrole:  0.9999\n",
      "utterancevec() syntacticrole:  0.7719\n",
      "The cook probably prepares the fish.\n",
      "\n",
      "semanticdepparse(): e: prepares  a: cook  p: fish\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7257\n",
      "utterancevec() morphologyrole:  0.9999\n",
      "utterancevec() syntacticrole:  0.7792\n",
      "The cook probably prepares a fish.\n",
      "\n",
      "semanticdepparse(): e: prepares  a: cook  p: fish\n",
      "utterancevec() lexicon:  0.0\n",
      "utterancevec() morphology:  0.7262\n",
      "utterancevec() morphologyrole:  0.9999\n",
      "utterancevec() syntacticrole:  0.7799\n"
     ]
    }
   ],
   "source": [
    "initunittest(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utterancespace = {}\n",
    "for i in dependencyanalysisstore:\n",
    "    utterancespace[i]=utterancevector(dependencyanalysisstore[i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cook bakes a pie.\n",
      "\n",
      "           0.9999   A cook bakes a pie.\n",
      "\n",
      "           0.2192   The cook makes the stew.\n",
      "\n",
      "           0.538   The cook does not bake a pie.\n",
      "\n",
      "           0.8396   The cook probably bakes a pie.\n",
      "\n",
      "           0.2001   The cook prepared the fish.\n",
      "\n",
      "           0.2201   The cook does not prepare a fish.\n",
      "\n",
      "           0.2053   The cook probably prepares the fish.\n",
      "\n",
      "           0.2001   The cook prepared fish.\n",
      "\n",
      "           0.2211   The cook probably prepares a fish.\n",
      "\n",
      "           0.5648   The cook bakes the cake.\n",
      "\n",
      "           0.2165   The cook prepared a fish.\n",
      "\n",
      "           0.5476   The cook makes a pie.\n",
      "The cook makes the stew.\n",
      "\n",
      "           0.2192   A cook bakes a pie.\n",
      "\n",
      "           1.0   The cook makes the stew.\n",
      "\n",
      "           0.3598   The cook does not bake a pie.\n",
      "\n",
      "           0.3116   The cook probably bakes a pie.\n",
      "\n",
      "           0.3188   The cook prepared the fish.\n",
      "\n",
      "           0.2927   The cook does not prepare a fish.\n",
      "\n",
      "           0.3072   The cook probably prepares the fish.\n",
      "\n",
      "           0.3188   The cook prepared fish.\n",
      "\n",
      "           0.3178   The cook probably prepares a fish.\n",
      "\n",
      "           0.3369   The cook bakes the cake.\n",
      "\n",
      "           0.3295   The cook prepared a fish.\n",
      "\n",
      "           0.6627   The cook makes a pie.\n",
      "The cook does not bake a pie.\n",
      "\n",
      "           0.538   A cook bakes a pie.\n",
      "\n",
      "           0.3598   The cook makes the stew.\n",
      "\n",
      "           0.9999   The cook does not bake a pie.\n",
      "\n",
      "           0.6318   The cook probably bakes a pie.\n",
      "\n",
      "           0.3199   The cook prepared the fish.\n",
      "\n",
      "           0.3111   The cook does not prepare a fish.\n",
      "\n",
      "           0.3334   The cook probably prepares the fish.\n",
      "\n",
      "           0.3199   The cook prepared fish.\n",
      "\n",
      "           0.3443   The cook probably prepares a fish.\n",
      "\n",
      "           0.3423   The cook bakes the cake.\n",
      "\n",
      "           0.3311   The cook prepared a fish.\n",
      "\n",
      "           0.6441   The cook makes a pie.\n",
      "The cook probably bakes a pie.\n",
      "\n",
      "           0.8396   A cook bakes a pie.\n",
      "\n",
      "           0.3116   The cook makes the stew.\n",
      "\n",
      "           0.6318   The cook does not bake a pie.\n",
      "\n",
      "           1.0   The cook probably bakes a pie.\n",
      "\n",
      "           0.3142   The cook prepared the fish.\n",
      "\n",
      "           0.3212   The cook does not prepare a fish.\n",
      "\n",
      "           0.4084   The cook probably prepares the fish.\n",
      "\n",
      "           0.3142   The cook prepared fish.\n",
      "\n",
      "           0.4229   The cook probably prepares a fish.\n",
      "\n",
      "           0.6471   The cook bakes the cake.\n",
      "\n",
      "           0.3292   The cook prepared a fish.\n",
      "\n",
      "           0.6221   The cook makes a pie.\n",
      "The cook prepared the fish.\n",
      "\n",
      "           0.2001   A cook bakes a pie.\n",
      "\n",
      "           0.3188   The cook makes the stew.\n",
      "\n",
      "           0.3199   The cook does not bake a pie.\n",
      "\n",
      "           0.3142   The cook probably bakes a pie.\n",
      "\n",
      "           1.0   The cook prepared the fish.\n",
      "\n",
      "           0.5794   The cook does not prepare a fish.\n",
      "\n",
      "           0.6713   The cook probably prepares the fish.\n",
      "\n",
      "           1.0   The cook prepared fish.\n",
      "\n",
      "           0.5696   The cook probably prepares a fish.\n",
      "\n",
      "           0.3329   The cook bakes the cake.\n",
      "\n",
      "           0.8913   The cook prepared a fish.\n",
      "\n",
      "           0.315   The cook makes a pie.\n",
      "The cook does not prepare a fish.\n",
      "\n",
      "           0.2201   A cook bakes a pie.\n",
      "\n",
      "           0.2927   The cook makes the stew.\n",
      "\n",
      "           0.3111   The cook does not bake a pie.\n",
      "\n",
      "           0.3212   The cook probably bakes a pie.\n",
      "\n",
      "           0.5794   The cook prepared the fish.\n",
      "\n",
      "           1.0   The cook does not prepare a fish.\n",
      "\n",
      "           0.5546   The cook probably prepares the fish.\n",
      "\n",
      "           0.5794   The cook prepared fish.\n",
      "\n",
      "           0.6454   The cook probably prepares a fish.\n",
      "\n",
      "           0.3397   The cook bakes the cake.\n",
      "\n",
      "           0.6743   The cook prepared a fish.\n",
      "\n",
      "           0.2904   The cook makes a pie.\n",
      "The cook probably prepares the fish.\n",
      "\n",
      "           0.2053   A cook bakes a pie.\n",
      "\n",
      "           0.3072   The cook makes the stew.\n",
      "\n",
      "           0.3334   The cook does not bake a pie.\n",
      "\n",
      "           0.4084   The cook probably bakes a pie.\n",
      "\n",
      "           0.6713   The cook prepared the fish.\n",
      "\n",
      "           0.5546   The cook does not prepare a fish.\n",
      "\n",
      "           1.0   The cook probably prepares the fish.\n",
      "\n",
      "           0.6713   The cook prepared fish.\n",
      "\n",
      "           0.9019   The cook probably prepares a fish.\n",
      "\n",
      "           0.316   The cook bakes the cake.\n",
      "\n",
      "           0.568   The cook prepared a fish.\n",
      "\n",
      "           0.3132   The cook makes a pie.\n",
      "The cook prepared fish.\n",
      "\n",
      "           0.2001   A cook bakes a pie.\n",
      "\n",
      "           0.3188   The cook makes the stew.\n",
      "\n",
      "           0.3199   The cook does not bake a pie.\n",
      "\n",
      "           0.3142   The cook probably bakes a pie.\n",
      "\n",
      "           1.0   The cook prepared the fish.\n",
      "\n",
      "           0.5794   The cook does not prepare a fish.\n",
      "\n",
      "           0.6713   The cook probably prepares the fish.\n",
      "\n",
      "           1.0   The cook prepared fish.\n",
      "\n",
      "           0.5696   The cook probably prepares a fish.\n",
      "\n",
      "           0.3329   The cook bakes the cake.\n",
      "\n",
      "           0.8913   The cook prepared a fish.\n",
      "\n",
      "           0.315   The cook makes a pie.\n",
      "The cook probably prepares a fish.\n",
      "\n",
      "           0.2211   A cook bakes a pie.\n",
      "\n",
      "           0.3178   The cook makes the stew.\n",
      "\n",
      "           0.3443   The cook does not bake a pie.\n",
      "\n",
      "           0.4229   The cook probably bakes a pie.\n",
      "\n",
      "           0.5696   The cook prepared the fish.\n",
      "\n",
      "           0.6454   The cook does not prepare a fish.\n",
      "\n",
      "           0.9019   The cook probably prepares the fish.\n",
      "\n",
      "           0.5696   The cook prepared fish.\n",
      "\n",
      "           1.0   The cook probably prepares a fish.\n",
      "\n",
      "           0.331   The cook bakes the cake.\n",
      "\n",
      "           0.6727   The cook prepared a fish.\n",
      "\n",
      "           0.3158   The cook makes a pie.\n",
      "The cook bakes the cake.\n",
      "\n",
      "           0.5648   A cook bakes a pie.\n",
      "\n",
      "           0.3369   The cook makes the stew.\n",
      "\n",
      "           0.3423   The cook does not bake a pie.\n",
      "\n",
      "           0.6471   The cook probably bakes a pie.\n",
      "\n",
      "           0.3329   The cook prepared the fish.\n",
      "\n",
      "           0.3397   The cook does not prepare a fish.\n",
      "\n",
      "           0.316   The cook probably prepares the fish.\n",
      "\n",
      "           0.3329   The cook prepared fish.\n",
      "\n",
      "           0.331   The cook probably prepares a fish.\n",
      "\n",
      "           1.0   The cook bakes the cake.\n",
      "\n",
      "           0.3484   The cook prepared a fish.\n",
      "\n",
      "           0.3506   The cook makes a pie.\n",
      "The cook prepared a fish.\n",
      "\n",
      "           0.2165   A cook bakes a pie.\n",
      "\n",
      "           0.3295   The cook makes the stew.\n",
      "\n",
      "           0.3311   The cook does not bake a pie.\n",
      "\n",
      "           0.3292   The cook probably bakes a pie.\n",
      "\n",
      "           0.8913   The cook prepared the fish.\n",
      "\n",
      "           0.6743   The cook does not prepare a fish.\n",
      "\n",
      "           0.568   The cook probably prepares the fish.\n",
      "\n",
      "           0.8913   The cook prepared fish.\n",
      "\n",
      "           0.6727   The cook probably prepares a fish.\n",
      "\n",
      "           0.3484   The cook bakes the cake.\n",
      "\n",
      "           1.0   The cook prepared a fish.\n",
      "\n",
      "           0.3175   The cook makes a pie.\n",
      "The cook makes a pie.\n",
      "           0.5476   A cook bakes a pie.\n",
      "\n",
      "           0.6627   The cook makes the stew.\n",
      "\n",
      "           0.6441   The cook does not bake a pie.\n",
      "\n",
      "           0.6221   The cook probably bakes a pie.\n",
      "\n",
      "           0.315   The cook prepared the fish.\n",
      "\n",
      "           0.2904   The cook does not prepare a fish.\n",
      "\n",
      "           0.3132   The cook probably prepares the fish.\n",
      "\n",
      "           0.315   The cook prepared fish.\n",
      "\n",
      "           0.3158   The cook probably prepares a fish.\n",
      "\n",
      "           0.3506   The cook bakes the cake.\n",
      "\n",
      "           0.3175   The cook prepared a fish.\n",
      "\n",
      "           1.0   The cook makes a pie.\n"
     ]
    }
   ],
   "source": [
    "rununittest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=semanticdepparse(\"The cat eats fish.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=utterancevector(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'599': 31.2161,\n",
       " '1239': -40.7035,\n",
       " '889': -1.3539,\n",
       " '954': 20.8136,\n",
       " '259': 4.52909,\n",
       " '1187': -16.0684,\n",
       " '1790': -41.3121,\n",
       " '54': 9.54726,\n",
       " '1662': -3.77058,\n",
       " '331': -10.8802,\n",
       " '1773': -26.285,\n",
       " '1100': -0.738639,\n",
       " '1194': -20.0026,\n",
       " '144': 27.5312,\n",
       " '256': 6.90189,\n",
       " '521': 1.26178,\n",
       " '465': 5.17814,\n",
       " '24': 8.6721,\n",
       " '981': -13.2477,\n",
       " '821': -18.1422,\n",
       " '1983': 0.827538,\n",
       " '984': 137.21,\n",
       " '366': 10.7486,\n",
       " '369': 37.2503,\n",
       " '1931': 5.82433,\n",
       " '1960': -11.1356,\n",
       " '1425': -12.4555,\n",
       " '262': -46.6341,\n",
       " '1026': 10.1527,\n",
       " '1495': -16.3532,\n",
       " '26': 0.674334,\n",
       " '392': -0.91982,\n",
       " '1737': -23.1944,\n",
       " '171': 8.28291,\n",
       " '802': -33.8708,\n",
       " '1532': 11.5401,\n",
       " '1573': -6.66549,\n",
       " '617': -27.8444,\n",
       " '1398': 11.7392,\n",
       " '1797': -20.1659,\n",
       " '1980': 16.8598,\n",
       " '1957': -30.9232,\n",
       " '734': 17.9864,\n",
       " '431': 11.6512,\n",
       " '1407': -17.2175,\n",
       " '1150': -6.97618,\n",
       " '261': -7.77552,\n",
       " '1314': -45.7488,\n",
       " '1226': 8.78049,\n",
       " '917': -2.13917,\n",
       " '651': -8.37052,\n",
       " '371': -17.9453,\n",
       " '1578': 6.70309,\n",
       " '339': 12.4702,\n",
       " '993': -12.7433,\n",
       " '1584': -9.73222,\n",
       " '1171': -2.21819,\n",
       " '514': 3.88896,\n",
       " '863': -11.3446,\n",
       " '1849': 8.92124,\n",
       " '1810': -1.98195,\n",
       " '1566': 9.00659,\n",
       " '39': 13.3744,\n",
       " '1910': -7.43151,\n",
       " '56': 20.8101,\n",
       " '1514': -8.01755,\n",
       " '1815': 20.72,\n",
       " '18': 2.59768,\n",
       " '1488': -52.8269,\n",
       " '1900': 16.2438,\n",
       " '628': -22.1437,\n",
       " '346': -1.99047,\n",
       " '1296': -26.1847,\n",
       " '388': 13.6174,\n",
       " '1473': 24.2186,\n",
       " '1518': 13.8321,\n",
       " '1924': -6.13867,\n",
       " '1442': -1.65976,\n",
       " '305': 25.361,\n",
       " '65': 20.3116,\n",
       " '133': 6.83949,\n",
       " '1055': -4.89091,\n",
       " '706': 3.09141,\n",
       " '1767': 8.45904,\n",
       " '378': 8.77946,\n",
       " '1030': 1.1098,\n",
       " '1417': 24.4236,\n",
       " '179': -4.13904,\n",
       " '461': 10.309,\n",
       " '796': 3.60399,\n",
       " '762': -9.00434,\n",
       " '1684': 5.60386,\n",
       " '652': -9.40986,\n",
       " '1949': 54.7072,\n",
       " '1907': 58.0637,\n",
       " '1015': -24.7683,\n",
       " '269': 5.87332,\n",
       " '156': -14.2344,\n",
       " '386': -14.8544,\n",
       " '45': 28.2757,\n",
       " '196': -6.13088,\n",
       " '1882': 14.5886,\n",
       " '1554': -4.93402,\n",
       " '241': 1.33414,\n",
       " '1421': 0.54818,\n",
       " '938': -0.598924,\n",
       " '693': 3.01043,\n",
       " '1418': 2.37601,\n",
       " '1501': -4.6326,\n",
       " '1463': 3.28113,\n",
       " '1940': -4.20126,\n",
       " '718': 27.6589,\n",
       " '699': 13.5943,\n",
       " '1419': 18.1944,\n",
       " '1681': 20.1294,\n",
       " '442': -16.1275,\n",
       " '1865': -14.7299,\n",
       " '522': -2.1723,\n",
       " '579': 3.6968,\n",
       " '105': -29.0314,\n",
       " '1500': 20.5083,\n",
       " '1161': 18.8511,\n",
       " '78': 13.2054,\n",
       " '1379': 6.97957,\n",
       " '1318': 6.1011,\n",
       " '264': 5.34166,\n",
       " '646': 6.35084,\n",
       " '47': 15.2201,\n",
       " '538': 53.6855,\n",
       " '479': 1.2017,\n",
       " '1950': -8.08737,\n",
       " '325': -12.5669,\n",
       " '1001': 0.487894,\n",
       " '1359': -0.477314,\n",
       " '614': -1.31782,\n",
       " '1594': 34.1095,\n",
       " '1108': 3.72445,\n",
       " '645': 64.8443,\n",
       " '1699': -4.74744,\n",
       " '1967': -0.999025,\n",
       " '947': -4.05496,\n",
       " '311': 9.88637,\n",
       " '636': -3.62443,\n",
       " '976': 0.69302,\n",
       " '1361': 22.612,\n",
       " '1019': -0.582973,\n",
       " '1869': 37.4578,\n",
       " '428': -17.1098,\n",
       " '149': -18.1729,\n",
       " '500': -6.53088,\n",
       " '671': 4.03985,\n",
       " '1378': 6.52083,\n",
       " '485': -13.8662,\n",
       " '1708': -10.6557,\n",
       " '140': -7.95577,\n",
       " '466': -10.989,\n",
       " '1539': 12.7687,\n",
       " '284': 13.9071,\n",
       " '1458': -18.8286,\n",
       " '222': 8.2058,\n",
       " '444': 21.5855,\n",
       " '1156': 4.00916,\n",
       " '1588': 0.949558,\n",
       " '1334': 9.64913,\n",
       " '504': -4.70462,\n",
       " '1123': -16.7998,\n",
       " '377': -12.657,\n",
       " '1769': -1.07144,\n",
       " '1406': 13.3294,\n",
       " '1220': 35.4898,\n",
       " '1013': -31.8793,\n",
       " '1446': -19.5702,\n",
       " '255': -5.18491,\n",
       " '983': 147.99,\n",
       " '833': 12.6971,\n",
       " '923': -2.4294,\n",
       " '419': 3.55056,\n",
       " '899': 16.9141,\n",
       " '1853': -3.49024,\n",
       " '1225': -29.2524,\n",
       " '1529': 65.0404,\n",
       " '398': -7.78631,\n",
       " '432': 20.4846,\n",
       " '1084': -12.1682,\n",
       " '701': -7.8382,\n",
       " '361': -80.0959,\n",
       " '853': 10.1892,\n",
       " '518': -48.8829,\n",
       " '1262': 23.6313,\n",
       " '1883': -18.2981,\n",
       " '929': -16.7055,\n",
       " '1545': 4.98316,\n",
       " '517': 13.1192,\n",
       " '1164': 13.6279,\n",
       " '1487': 24.6261,\n",
       " '556': -60.4211,\n",
       " '936': -10.4978,\n",
       " '1936': -19.3024,\n",
       " '192': -72.6633,\n",
       " '1402': -6.19591,\n",
       " '562': -16.0262,\n",
       " '1409': -43.2006,\n",
       " '1994': -332.238,\n",
       " '1007': 1.16448,\n",
       " '1512': -3.80268,\n",
       " '999': -11.2322,\n",
       " '986': 20.8862,\n",
       " '1651': 17.0042,\n",
       " '793': -2.97957,\n",
       " '1310': 26.6191,\n",
       " '1908': 10.561,\n",
       " '1078': 36.648,\n",
       " '961': 16.4505,\n",
       " '541': -26.7874,\n",
       " '434': -5.02467,\n",
       " '731': 1.53,\n",
       " '1803': -4.1675,\n",
       " '1568': 12.1538,\n",
       " '1534': -1.33914,\n",
       " '1202': 2.3176,\n",
       " '1520': -7.12923,\n",
       " '1945': -7.1312,\n",
       " '902': 5.58894,\n",
       " '306': 1.33253,\n",
       " '1597': -26.1245,\n",
       " '285': 66.1596,\n",
       " '982': 11.355,\n",
       " '1570': -26.5073,\n",
       " '1995': -20.3938,\n",
       " '1457': -2.49881,\n",
       " '332': 19.8422,\n",
       " '1670': -19.3295,\n",
       " '824': -16.3884,\n",
       " '1813': -2.28011,\n",
       " '112': -9.27469,\n",
       " '669': 6.03634,\n",
       " '1701': 6.63839,\n",
       " '1386': 1.68782,\n",
       " '69': 26.1781,\n",
       " '638': -3.70369,\n",
       " '110': -7.09135,\n",
       " '1941': -1.49579,\n",
       " '862': -2.68696,\n",
       " '748': -4.55902,\n",
       " '1389': 25.7433,\n",
       " '1025': -22.4991,\n",
       " '146': 36.6154,\n",
       " '1683': 10.6302,\n",
       " '1294': -6.28219,\n",
       " '1253': -8.95563,\n",
       " '1328': 23.5501,\n",
       " '1180': -5.99365,\n",
       " '248': -67.531,\n",
       " '974': 4.04544,\n",
       " '1717': -2.43656,\n",
       " '1802': -2.15433,\n",
       " '565': 9.89468,\n",
       " '84': -4.26389,\n",
       " '1011': -30.7854,\n",
       " '1506': 59.3657,\n",
       " '347': -6.18601,\n",
       " '1008': -26.5069,\n",
       " '964': -3.79338,\n",
       " '1582': 3.57541,\n",
       " '1659': -6.36435,\n",
       " '1363': 299.376,\n",
       " '1668': 1.88969,\n",
       " '678': 11.5069,\n",
       " '1254': 310.141,\n",
       " '1642': -11.3391,\n",
       " '464': 2.94822,\n",
       " '1992': -16.1038,\n",
       " '1729': -2.13702,\n",
       " '1745': -38.1874,\n",
       " '433': -7.10449,\n",
       " '1303': -11.5517,\n",
       " '845': -10.9757,\n",
       " '880': -3.27892,\n",
       " '1048': 19.5959,\n",
       " '784': -12.5255,\n",
       " '385': -14.4105,\n",
       " '301': -2.27958,\n",
       " '546': 30.1121,\n",
       " '1413': 4.2893,\n",
       " '42': 33.4948,\n",
       " '1383': -9.44453,\n",
       " '1913': -26.163,\n",
       " '1170': -10.328,\n",
       " '293': 6.16363,\n",
       " '928': -24.0491,\n",
       " '1306': -2.36818,\n",
       " '956': -13.8763,\n",
       " '837': -14.2704,\n",
       " '737': 3.68171,\n",
       " '856': 6.72031,\n",
       " '1839': -2.50706,\n",
       " '279': 1.37109,\n",
       " '1340': 2.88614,\n",
       " '1354': 53.1341,\n",
       " '454': 5.80122,\n",
       " '315': -1.25532,\n",
       " '205': 23.9359,\n",
       " '1173': -6.17068,\n",
       " '1470': -15.8371,\n",
       " '1912': 8.13696,\n",
       " '620': -4.15331,\n",
       " '1222': 6.89512,\n",
       " '1157': -4.11152,\n",
       " '383': -7.7567,\n",
       " '875': 9.25292,\n",
       " '733': -4.416,\n",
       " '235': -1.06542,\n",
       " '302': 13.785,\n",
       " '758': 23.2426,\n",
       " '873': 1.09596,\n",
       " '510': 2.47338,\n",
       " '972': -1.0284,\n",
       " '583': 13.9519,\n",
       " '1747': -7.10552,\n",
       " '1986': 25.4734,\n",
       " '1228': 13.8678,\n",
       " '1801': -0.474436,\n",
       " '1716': -2.67484,\n",
       " '1219': 19.9049,\n",
       " '543': 12.7639,\n",
       " '1255': 10.9601,\n",
       " '1135': 3.30411,\n",
       " '760': 1.16673,\n",
       " '19': -6.47504,\n",
       " '750': 1.47124,\n",
       " '1752': -11.7289,\n",
       " '246': 4.6531,\n",
       " '1451': -2.29528,\n",
       " '1944': -17.7266,\n",
       " '704': -1.41431,\n",
       " '338': -30.6653,\n",
       " '1714': 10.0065,\n",
       " '1411': -45.2223,\n",
       " '1469': 9.47338,\n",
       " '1658': 34.3905,\n",
       " '2': -2.60338,\n",
       " '486': -27.3278,\n",
       " '851': -35.4538,\n",
       " '1688': -18.9284,\n",
       " '973': -6.38105,\n",
       " '99': 3.82446,\n",
       " '420': 10.6504,\n",
       " '1006': 17.043,\n",
       " '159': -20.6996,\n",
       " '1264': -0.0625057,\n",
       " '25': 31.2875,\n",
       " '1733': -2.81086,\n",
       " '463': -16.8676,\n",
       " '408': 38.2277,\n",
       " '1046': -7.3477,\n",
       " '1723': -0.585655,\n",
       " '1579': 7.77524,\n",
       " '1806': -19.6065,\n",
       " '319': 7.49883,\n",
       " '809': 0.677829,\n",
       " '182': 55.3814,\n",
       " '1186': 7.2323,\n",
       " '1763': 13.3634,\n",
       " '1556': -3.23824,\n",
       " '1692': -15.1784,\n",
       " '1312': 12.0891,\n",
       " '1246': 15.3239,\n",
       " '1777': 39.3262,\n",
       " '1034': -14.0304,\n",
       " '136': 3.70238,\n",
       " '843': 0.473493,\n",
       " '322': 2.10927,\n",
       " '186': 3.82671,\n",
       " '307': 45.0454,\n",
       " '137': 16.9812,\n",
       " '1739': -9.01631,\n",
       " '673': 11.8177,\n",
       " '1497': 4.96804,\n",
       " '1827': -42.5297,\n",
       " '1774': -21.9893,\n",
       " '876': 11.3431,\n",
       " '132': -66.9298,\n",
       " '1113': 1.88239,\n",
       " '1833': 7.11498,\n",
       " '1282': -41.3229,\n",
       " '1575': 1.78373,\n",
       " '810': 10.9711,\n",
       " '243': -4.48782,\n",
       " '904': 0.421747,\n",
       " '181': -41.5219,\n",
       " '867': 79.0979,\n",
       " '1804': -2.09451,\n",
       " '1345': 7.13961,\n",
       " '1198': 2.31034,\n",
       " '365': 2.55256,\n",
       " '1845': 6.99228,\n",
       " '643': -3.94492,\n",
       " '1510': -13.4639,\n",
       " '1929': -64.3294,\n",
       " '705': 23.6451,\n",
       " '768': 3.66091,\n",
       " '1775': -44.6385,\n",
       " '418': 28.0214,\n",
       " '1210': -3.29734,\n",
       " '507': -5.84461,\n",
       " '66': 27.2618,\n",
       " '1129': -8.08457,\n",
       " '429': 15.8088,\n",
       " '1697': 13.1592,\n",
       " '540': 14.6751,\n",
       " '1979': -2.02099,\n",
       " '396': 0.0731739,\n",
       " '1341': 10.7606,\n",
       " '989': -1.02767,\n",
       " '1917': 11.6624,\n",
       " '368': -3.60047,\n",
       " '1779': 21.7139,\n",
       " '416': 4.94767,\n",
       " '93': 1.46986,\n",
       " '1110': -0.988269,\n",
       " '1377': 5.34885,\n",
       " '165': 19.4886,\n",
       " '1667': 3.06005,\n",
       " '664': -29.5827,\n",
       " '765': 30.0569,\n",
       " '1875': -4.26611,\n",
       " '1706': 5.51349,\n",
       " '375': -1.78873,\n",
       " '642': 1.42001,\n",
       " '576': -2.14314,\n",
       " '1746': -6.7043,\n",
       " '1611': 0.135299,\n",
       " '231': 8.02835,\n",
       " '191': 8.55057,\n",
       " '123': -42.6115,\n",
       " '700': -2.41886,\n",
       " '819': -16.8133,\n",
       " '334': -11.1168,\n",
       " '1633': 2.08472,\n",
       " '462': 16.0547,\n",
       " '509': -0.311248,\n",
       " '1485': 21.3858,\n",
       " '1649': 26.0803,\n",
       " '3': 19.0005,\n",
       " '1382': 59.2877,\n",
       " '1454': 0.20726,\n",
       " '335': 22.5311,\n",
       " '108': 24.1096,\n",
       " '1973': -6.59931,\n",
       " '1093': 0.0784125,\n",
       " '571': 28.465,\n",
       " '1387': -7.20601,\n",
       " '254': -15.6372,\n",
       " '777': -31.4595,\n",
       " '1664': -1.47408,\n",
       " '530': 39.7222,\n",
       " '764': -28.3003,\n",
       " '1557': 5.31452,\n",
       " '493': 9.3396,\n",
       " '1756': -1.60841,\n",
       " '487': 11.0418,\n",
       " '447': -23.5872,\n",
       " '1704': -4.43349,\n",
       " '505': -64.4816,\n",
       " '831': 14.675,\n",
       " '1636': -49.7074,\n",
       " '1184': 34.8663,\n",
       " '515': 14.9744,\n",
       " '213': 0.369357,\n",
       " '95': -5.9633,\n",
       " '468': -52.9299,\n",
       " '730': 6.04635,\n",
       " '1045': -15.7643,\n",
       " '1753': -4.26599,\n",
       " '272': 10.0591,\n",
       " '1352': -37.6685,\n",
       " '751': -29.8857,\n",
       " '761': 16.7003,\n",
       " '1997': -10.2539,\n",
       " '1878': -3.33084,\n",
       " '743': -4.91831,\n",
       " '1631': 4.5303,\n",
       " '29': 3.89931,\n",
       " '654': 1.47247,\n",
       " '230': 12.7149,\n",
       " '1348': -5.72495,\n",
       " '1522': -24.744,\n",
       " '1969': -6.81623,\n",
       " '1267': -0.398568,\n",
       " '1207': -23.3006,\n",
       " '1063': 13.9103,\n",
       " '948': -25.3602,\n",
       " '1880': -8.2333,\n",
       " '318': -24.3158,\n",
       " '520': 0.0116616,\n",
       " '1725': 21.7845,\n",
       " '1771': -29.7288,\n",
       " '1443': 5.62172,\n",
       " '601': 11.5947,\n",
       " '1369': 22.2698,\n",
       " '1496': 28.1092,\n",
       " '1754': -34.6237,\n",
       " '1730': -22.6743,\n",
       " '1405': -26.0582,\n",
       " '1076': 7.92844,\n",
       " '529': 7.95517,\n",
       " '313': -25.9658,\n",
       " '1251': 9.42358,\n",
       " '1353': -12.6631,\n",
       " '118': -17.4569,\n",
       " '1215': 20.9633,\n",
       " '773': -15.6109,\n",
       " '288': -15.1879,\n",
       " '1372': 6.07735,\n",
       " '1146': -2.41774,\n",
       " '1990': -16.7932,\n",
       " '660': -13.2909,\n",
       " '1918': -58.0748,\n",
       " '425': -7.40212,\n",
       " '1450': 327.466,\n",
       " '1528': -22.3684,\n",
       " '401': -17.5802,\n",
       " '1655': 1.50716,\n",
       " '755': 16.8953,\n",
       " '1943': 0.170592,\n",
       " '747': -20.2055,\n",
       " '754': 9.27706,\n",
       " '379': -7.79847,\n",
       " '1859': -16.0982,\n",
       " '79': -10.0726,\n",
       " '1580': -46.8874,\n",
       " '228': -0.116164,\n",
       " '172': 48.1347,\n",
       " '1346': 3.3636,\n",
       " '886': 32.2323,\n",
       " '296': -5.9671,\n",
       " '879': -1.79052,\n",
       " '766': -22.2152,\n",
       " '1971': 20.8564,\n",
       " '197': 1.82278,\n",
       " '1395': 10.7436,\n",
       " '812': -7.72023,\n",
       " '502': -5.98639,\n",
       " '152': -5.55871,\n",
       " '626': -9.02879,\n",
       " '312': 42.8842,\n",
       " '374': -38.7166,\n",
       " '1344': -19.9561,\n",
       " '1216': 6.8564,\n",
       " '854': -20.7077,\n",
       " '1117': 6.93896,\n",
       " '826': -8.67384,\n",
       " '1493': 5.61582,\n",
       " '1085': -2.95309,\n",
       " '1060': 158.815,\n",
       " '1031': 5.07559,\n",
       " '190': -27.8776,\n",
       " '208': 4.08104,\n",
       " '291': 11.313,\n",
       " '15': 4.4747,\n",
       " '544': 8.65588,\n",
       " '1484': -35.5899,\n",
       " '1258': 25.7679,\n",
       " '668': -6.19625,\n",
       " '511': 46.9524,\n",
       " '1954': 24.5732,\n",
       " '712': -8.18045,\n",
       " '12': 17.1403,\n",
       " '17': -0.495011,\n",
       " '1799': -2.05983,\n",
       " '1808': -7.57649,\n",
       " '551': 5.78064,\n",
       " '613': -2.80085,\n",
       " '513': 1.499,\n",
       " '881': 6.34803,\n",
       " '448': -0.667628,\n",
       " '1521': 9.99568,\n",
       " '920': -2.77428,\n",
       " '1441': -6.98978,\n",
       " '1433': -2.97252,\n",
       " '76': 0.602949,\n",
       " '1350': 15.0489,\n",
       " '723': -29.2566,\n",
       " '1639': -15.0305,\n",
       " '1694': -11.7935,\n",
       " '631': 9.44497,\n",
       " '1088': -6.27765,\n",
       " '799': 5.87688,\n",
       " '1728': -3.17697,\n",
       " '1620': -3.65232,\n",
       " '1003': -5.68467,\n",
       " '969': 10.8324,\n",
       " '1408': 3.12028,\n",
       " '1062': -6.64051,\n",
       " '1887': -7.76028,\n",
       " '978': -3.18635,\n",
       " '44': 4.07321,\n",
       " '1200': -21.6041,\n",
       " '1087': -14.8782,\n",
       " '1975': 21.8715,\n",
       " '767': 39.6642,\n",
       " '1109': -11.6803,\n",
       " '430': -27.1761,\n",
       " '1492': -8.42952,\n",
       " '440': -9.18283,\n",
       " '732': 35.0633,\n",
       " '508': -7.57749,\n",
       " '695': 2.25944,\n",
       " '1308': -8.43901,\n",
       " '451': -1.6196,\n",
       " '350': 10.1614,\n",
       " '1871': 17.1546,\n",
       " '640': 68.8939,\n",
       " '1915': -28.8242,\n",
       " '389': -24.7713,\n",
       " '43': 24.3365,\n",
       " '406': -22.5623,\n",
       " '11': -10.4281,\n",
       " '1687': 6.08883,\n",
       " '457': 5.92038,\n",
       " '357': 11.7795,\n",
       " '578': 54.3746,\n",
       " '1276': -7.87219,\n",
       " '1431': 22.3764,\n",
       " '86': -13.9817,\n",
       " '1489': -2.18413,\n",
       " '1302': 3.16698,\n",
       " '1124': -5.13929,\n",
       " '37': -10.8458,\n",
       " '49': -14.3347,\n",
       " '1814': 9.69786,\n",
       " '711': -0.244664,\n",
       " '582': 5.8033,\n",
       " '345': 0.785452,\n",
       " '803': 6.47207,\n",
       " '180': 7.822,\n",
       " '1174': 12.2266,\n",
       " '1059': 13.9183,\n",
       " '1404': -35.2879,\n",
       " '270': -16.7055,\n",
       " '786': -22.7891,\n",
       " '1475': -20.0679,\n",
       " '1462': 34.9945,\n",
       " '1509': 13.0457,\n",
       " '584': -1.56758,\n",
       " '382': 46.3767,\n",
       " '492': -6.17672,\n",
       " '689': -7.71946,\n",
       " '1480': 16.1748,\n",
       " '113': 13.9728,\n",
       " '1385': -34.5001,\n",
       " '852': -3.09856,\n",
       " '31': -15.5598,\n",
       " '1837': 11.1887,\n",
       " '1384': -8.30384,\n",
       " '1731': -21.0316,\n",
       " '850': -14.1882,\n",
       " '1527': -15.6107,\n",
       " '703': 4.94216,\n",
       " '1896': -14.1694,\n",
       " '1208': -2.39689,\n",
       " '85': 14.2518,\n",
       " '297': -12.4836,\n",
       " '1988': -8.84482,\n",
       " '247': -30.5692,\n",
       " '1690': 2.2265,\n",
       " '915': 0.196443,\n",
       " '207': 1.9799,\n",
       " '225': 14.2689,\n",
       " '878': 17.8074,\n",
       " '1068': 45.1073,\n",
       " '1331': 5.89955,\n",
       " '1416': -5.62589,\n",
       " '1263': -14.0005,\n",
       " '1674': -13.825,\n",
       " '435': 0.0542484,\n",
       " '1638': -1.93239,\n",
       " '1399': 18.4288,\n",
       " '560': 20.7063,\n",
       " '692': 0.478123,\n",
       " '990': 2.73946,\n",
       " '1301': -11.751,\n",
       " '1440': 4.15333,\n",
       " '1981': -14.5803,\n",
       " '536': -36.4076,\n",
       " '1838': -11.059,\n",
       " '859': -25.424,\n",
       " '594': 3.15082,\n",
       " '901': 10.4748,\n",
       " '1993': -12.0819,\n",
       " '585': -6.17298,\n",
       " '1650': -17.7307,\n",
       " '1819': 0.173366,\n",
       " '625': -36.1423,\n",
       " '1248': 1.80736,\n",
       " '830': -4.20891,\n",
       " '1749': -12.7032,\n",
       " '1542': 27.8933,\n",
       " '687': 0.312104,\n",
       " '1513': -4.00938,\n",
       " '480': -15.4918,\n",
       " '1874': 4.19061,\n",
       " '239': 6.8275,\n",
       " '1185': -5.17001,\n",
       " '1127': 8.26675,\n",
       " '872': -10.6575,\n",
       " '825': 21.7214,\n",
       " '1732': -0.491219,\n",
       " '869': -1.16639,\n",
       " '141': -3.30228,\n",
       " '848': -40.0218,\n",
       " '1105': 7.24038,\n",
       " '968': 18.7766,\n",
       " '1152': -0.560732,\n",
       " '1043': -0.145577,\n",
       " '1585': -2.17024,\n",
       " '1787': -4.51201,\n",
       " '474': -9.57137,\n",
       " '271': -45.231,\n",
       " '114': -2.26773,\n",
       " '1772': 7.64224,\n",
       " '121': -65.436,\n",
       " '176': -22.5952,\n",
       " '857': 10.0993,\n",
       " '1358': 13.0768,\n",
       " '1682': 23.0767,\n",
       " '155': -7.20509,\n",
       " '423': -1.25207,\n",
       " '1': 30.8678,\n",
       " '1212': -4.02574,\n",
       " '1660': 5.79999,\n",
       " '1894': 12.9826,\n",
       " '1759': 48.0016,\n",
       " '89': 1.17361,\n",
       " '1793': 6.37789,\n",
       " '569': -1.89726,\n",
       " '1548': -54.3271,\n",
       " '403': -17.2167,\n",
       " '937': -0.338809,\n",
       " '1002': -8.24769,\n",
       " '967': -19.4241,\n",
       " '1051': -18.6453,\n",
       " '415': -10.8785,\n",
       " '348': 6.22909,\n",
       " '1277': 13.1253,\n",
       " '1295': -79.8542,\n",
       " '1320': 10.2519,\n",
       " '275': 1.13877,\n",
       " '1914': -1.22331,\n",
       " '567': 8.34642,\n",
       " '1909': -0.120023,\n",
       " '726': -16.6712,\n",
       " '340': 11.1721,\n",
       " '1010': -34.1154,\n",
       " '1292': -1.63384,\n",
       " '1153': 30.9458,\n",
       " '1099': 5.99794,\n",
       " '839': 12.3369,\n",
       " '1629': -10.1864,\n",
       " '1695': 11.789,\n",
       " '1555': -2.5986,\n",
       " '1541': 23.442,\n",
       " '412': 9.60137,\n",
       " '1423': -14.6768,\n",
       " '1230': -10.0509,\n",
       " '276': -3.65332,\n",
       " '785': 31.9622,\n",
       " '104': 6.10876,\n",
       " '1237': -3.33578,\n",
       " '722': -23.3777,\n",
       " '1400': 4.75396,\n",
       " '868': 7.12568,\n",
       " '1482': -3.70699,\n",
       " '1703': 11.0257,\n",
       " '27': -28.6958,\n",
       " '807': 11.8293,\n",
       " '1726': 4.68415,\n",
       " '527': 4.99377,\n",
       " '887': 19.5053,\n",
       " '1021': 18.9727,\n",
       " '1424': -11.3249,\n",
       " '885': -1.49931,\n",
       " '564': -89.1569,\n",
       " '1486': -8.46704,\n",
       " '497': 28.5549,\n",
       " '771': -7.37881,\n",
       " '1077': -5.42525,\n",
       " '355': 6.84143,\n",
       " '1201': -8.94101,\n",
       " '206': 9.84474,\n",
       " '924': 23.3146,\n",
       " '77': 0.365836,\n",
       " '1498': 5.4405,\n",
       " '1524': -1.70613,\n",
       " '51': -4.21355,\n",
       " '537': 6.37669,\n",
       " '1613': 34.5744,\n",
       " '250': -1.93275,\n",
       " '1038': -28.9522,\n",
       " '1401': 10.772,\n",
       " '210': -15.0658,\n",
       " '1278': 14.0205,\n",
       " '204': 2.4345,\n",
       " '358': -0.681464,\n",
       " '48': -6.5175,\n",
       " '1114': 0.961877,\n",
       " '16': 29.919,\n",
       " '1221': -2.21307,\n",
       " '1592': 7.07157,\n",
       " '214': -6.28354,\n",
       " '349': -4.04602,\n",
       " '975': -0.276689,\n",
       " '1149': -20.0671,\n",
       " '525': -2.96282,\n",
       " '1118': -20.4735,\n",
       " '1891': 11.2658,\n",
       " '1319': 11.0339,\n",
       " '702': -5.40241,\n",
       " '842': -6.6324,\n",
       " '997': -14.3132,\n",
       " '985': 37.7898,\n",
       " '1792': 128.612,\n",
       " '1020': 17.5661,\n",
       " '1689': 6.91769,\n",
       " '1850': 1.2557,\n",
       " '1195': 36.4411,\n",
       " '739': -3.19624,\n",
       " '580': -5.1902,\n",
       " '142': -22.124,\n",
       " '1621': -8.9969,\n",
       " '102': 4.18226,\n",
       " '597': 14.5571,\n",
       " '716': 48.7605,\n",
       " '1182': 21.1399,\n",
       " '1307': -21.5166,\n",
       " '475': -15.239,\n",
       " '268': 3.46386,\n",
       " '1028': -6.55234,\n",
       " '676': -4.41494,\n",
       " '1315': 17.7393,\n",
       " '952': 1.89139,\n",
       " '1214': -5.73731,\n",
       " '1033': -3.35231,\n",
       " '211': 326.733,\n",
       " '327': 1.31255,\n",
       " '1826': -35.4615,\n",
       " '757': 4.67934,\n",
       " '1677': 24.0888,\n",
       " '1017': 33.072,\n",
       " '1866': -2.1696,\n",
       " '1142': 14.2937,\n",
       " '827': -0.930916,\n",
       " '934': 10.7048,\n",
       " '404': -8.34781,\n",
       " '683': 5.2481,\n",
       " '135': 49.8232,\n",
       " '201': 177.183,\n",
       " '1696': -7.41777,\n",
       " '1188': 4.76308,\n",
       " '933': -7.44922,\n",
       " '1503': 5.97911,\n",
       " '87': 21.7129,\n",
       " '1830': -166.433,\n",
       " '1665': -5.26796,\n",
       " '1203': -8.01472,\n",
       " '1297': -29.8527,\n",
       " '1252': 14.9531,\n",
       " '698': -24.6952,\n",
       " '1299': -44.9233,\n",
       " '1707': -15.5465,\n",
       " '800': -12.4902,\n",
       " '1657': -7.1838,\n",
       " '1279': 32.8079,\n",
       " '865': -17.0531,\n",
       " '495': 9.09338,\n",
       " '1107': 26.0933,\n",
       " '267': 22.7539,\n",
       " '1844': -1.4237,\n",
       " '1702': -2.1225,\n",
       " '393': 19.5128,\n",
       " '1381': -11.9929,\n",
       " '323': -7.43916,\n",
       " '1351': -5.72935,\n",
       " '278': -4.97229,\n",
       " '891': 20.1498,\n",
       " '1183': -13.4978,\n",
       " '1249': 5.91666,\n",
       " '1096': -4.02992,\n",
       " '1776': 317.517,\n",
       " '1766': -5.85163,\n",
       " '1204': -21.5557,\n",
       " '157': -10.9102,\n",
       " '1872': -16.0998,\n",
       " '1686': -31.6848,\n",
       " '1877': -12.685,\n",
       " '1991': -25.453,\n",
       " '130': -10.2363,\n",
       " '4': 7.82603,\n",
       " '236': 36.8073,\n",
       " '1079': -3.43078,\n",
       " '1159': 5.21659,\n",
       " '888': -7.70497,\n",
       " '354': -2.06224,\n",
       " '174': -7.69877,\n",
       " '1057': 2.32019,\n",
       " '1335': -4.98928,\n",
       " '1476': -10.4635,\n",
       " '227': 43.2107,\n",
       " '1598': -6.54095,\n",
       " '1177': 24.1958,\n",
       " '685': 10.1606,\n",
       " '1112': -14.8979,\n",
       " '1432': 4.81829,\n",
       " '744': -6.08069,\n",
       " '1091': -2.81235,\n",
       " '97': -9.9435,\n",
       " '616': 11.5032,\n",
       " '33': -1.43327,\n",
       " '470': 7.66337,\n",
       " '789': -2.32217,\n",
       " '1760': 25.9992,\n",
       " '1825': -26.3912,\n",
       " '1234': 12.4131,\n",
       " '1181': 18.2882,\n",
       " '1192': -17.335,\n",
       " '1436': -28.9129,\n",
       " '971': 26.1152,\n",
       " '1615': -0.648809,\n",
       " '1576': 29.7219,\n",
       " '1778': -15.6212,\n",
       " '592': 36.6366,\n",
       " '1661': -10.1887,\n",
       " '963': -39.2441,\n",
       " '1876': 22.7969,\n",
       " '314': 12.7058,\n",
       " '1232': -1.91241,\n",
       " '1000': 4.31597,\n",
       " '740': 29.2752,\n",
       " '1138': -1.74171,\n",
       " '1083': 13.3937,\n",
       " '1899': -12.51,\n",
       " '1606': 1.35644,\n",
       " '1818': 12.4941,\n",
       " '1562': 7.02694,\n",
       " '1380': 13.3179,\n",
       " '40': 10.3254,\n",
       " '1271': 0.969724,\n",
       " '1572': -14.6909,\n",
       " '1921': 3.91777,\n",
       " '1168': 13.0549,\n",
       " '775': -20.5214,\n",
       " '1843': -16.0645,\n",
       " '139': 15.3134,\n",
       " '846': -24.3505,\n",
       " '813': 9.81332,\n",
       " '1634': -2.28675,\n",
       " '1919': 18.5756,\n",
       " '362': -18.4349,\n",
       " '445': -2.35675,\n",
       " '823': -1.53637,\n",
       " '1743': 7.08813,\n",
       " '772': -12.2572,\n",
       " '50': 12.7365,\n",
       " '1143': 1.41002,\n",
       " '1647': 1.1917,\n",
       " '675': -29.5458,\n",
       " '294': -61.0182,\n",
       " '289': -1.4508,\n",
       " '1698': 3.66817,\n",
       " '1058': 55.1219,\n",
       " '1080': 22.0493,\n",
       " '898': 8.46118,\n",
       " '650': 21.1845,\n",
       " '987': -12.5843,\n",
       " '1241': -6.30853,\n",
       " '1223': -7.46463,\n",
       " '535': -5.35419,\n",
       " '456': 11.577,\n",
       " '218': 7.98019,\n",
       " '1283': 1.00609,\n",
       " '1873': 10.7359,\n",
       " '966': 1.60859,\n",
       " '727': 6.04609,\n",
       " '209': 20.7457,\n",
       " '1397': -19.7938,\n",
       " '1355': 18.8463,\n",
       " '1605': -2.70884,\n",
       " '1343': -1.47034,\n",
       " '776': 8.68978,\n",
       " '666': -9.62223,\n",
       " '1193': 11.4613,\n",
       " '575': 3.49475,\n",
       " '1577': -1.24558,\n",
       " '109': -61.0623,\n",
       " '1630': -9.6595,\n",
       " '566': 5.13231,\n",
       " '950': -12.384,\n",
       " '1563': -3.54257,\n",
       " '1338': 4.05566,\n",
       " '882': -3.85349,\n",
       " ...}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorspace[c.patient.surfacestring]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showtree(sentence):\n",
    "    depgraph=dependency_parser.raw_parse(sentence.lower())\n",
    "    for deps in depgraph:\n",
    "        print(deps)\n",
    "        for nodeindex in deps.nodes:\n",
    "            print(deps.nodes[nodeindex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_loop(debug=False,moredebug=False):\n",
    "    instring = ''\n",
    "    prev=newrandomvector(dimensionality,denseness)\n",
    "    prevlex=newrandomvector(dimensionality,denseness)\n",
    "    prevsem=newrandomvector(dimensionality,denseness)\n",
    "    prevmor=newrandomvector(dimensionality,denseness)\n",
    "    prevmgn=newrandomvector(dimensionality,denseness)\n",
    "    while instring != 'quit':\n",
    "        try:\n",
    "            instring = input('> ')\n",
    "            s = instring.rstrip()\n",
    "            wds=nltk.word_tokenize(s.lower())\n",
    "            chkwordspace(wds,debug)\n",
    "            try:\n",
    "                c = semanticdepparse(s.lower(),debug)\n",
    "                u = utterancevector(c,moredebug, True, True, False, False,False)\n",
    "                print(\" lexical     \",sparsecosine(prev,u),end=\"\\t(\")\n",
    "                print(sparsecosine(prevlex,u),\")\")\n",
    "                prevlex=u\n",
    "                u = utterancevector(c,moredebug, True, False, False, True, False)\n",
    "                print(\" semrole     \",sparsecosine(prev,u),end=\"\\t(\")\n",
    "                print(sparsecosine(prevsem,u),\")\")\n",
    "                prevsem=u\n",
    "                u = utterancevector(c,moredebug, True, False, True, False, False)\n",
    "                print(\" morph     \",sparsecosine(prev,u),end=\"\\t(\")\n",
    "                print(sparsecosine(prevmor,u),\")\")\n",
    "                prevmor=u\n",
    "                u = utterancevector(c,moredebug, True, False, False, False, True)\n",
    "                print(\" morphgen  \",sparsecosine(prev,u),end=\"\\t(\")\n",
    "                print(sparsecosine(prevmgn,u),\")\")\n",
    "                prevmgn=u\n",
    "                u = utterancevector(c,moredebug, True)\n",
    "                print(\" in toto     \",sparsecosine(prev,u))\n",
    "                prev = u\n",
    "            except:\n",
    "                print(\"****\")\n",
    "        except:\n",
    "            print(\"hey!\")\n",
    "            instring = 'quit'\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> The cat eats the fish.\n",
      "semanticdepparse(): e: eats  a: cat  p: fish\n",
      " lexical      0.0\t(-0.0155 )\n",
      " semrole      0.0\t(0.0 )\n",
      " morph      0.0399\t(-0.0126 )\n",
      " morphgen   -0.0259\t(-0.0518 )\n",
      " in toto      0.0069\n",
      "> The cat eats the meat.\n",
      "semanticdepparse(): e: eats  a: cat  p: meat\n",
      " lexical      0.4106\t(0.693 )\n",
      " semrole      0.3376\t(0.6666 )\n",
      " morph      0.326\t(0.6713 )\n",
      " morphgen   0.5005\t(1.0 )\n",
      " in toto      0.7682\n",
      "> we eat the meat\n",
      "semanticdepparse(): e: eat  a: we  p: meat\n",
      " lexical      0.2202\t(0.4218 )\n",
      " semrole      0.1635\t(0.3333 )\n",
      " morph      0.2536\t(0.4389 )\n",
      " morphgen   0.501\t(1.0 )\n",
      " in toto      0.5519\n",
      "> we eat the fish\n",
      "semanticdepparse(): e: eat  a: we  p: fish\n",
      " lexical      0.3455\t(0.6908 )\n",
      " semrole      0.3634\t(0.6666 )\n",
      " morph      0.3583\t(0.6578 )\n",
      " morphgen   0.5142\t(1.0 )\n",
      " in toto      0.7671\n",
      "> we do not eat the fish\n",
      "semanticdepparse(): e: eat  a: we  p: fish\n",
      " lexical      0.5247\t(1.0 )\n",
      " semrole      0.4366\t(0.866 )\n",
      " morph      0.5\t(1.0 )\n",
      " morphgen   0.5206\t(1.0 )\n",
      " in toto      0.9622\n",
      "> we probably will eat the fish\n",
      "semanticdepparse(): e: eat  a: we  p: fish\n",
      " lexical      0.5044\t(1.0 )\n",
      " semrole      0.4461\t(0.75 )\n",
      " morph      0.4687\t(1.0 )\n",
      " morphgen   0.5108\t(1.0 )\n",
      " in toto      0.9268\n",
      "> we will eat meat\n",
      "semanticdepparse(): e: eat  a: we  p: meat\n",
      " lexical      0.3664\t(0.6908 )\n",
      " semrole      0.3447\t(0.5773 )\n",
      " morph      0.3258\t(0.6578 )\n",
      " morphgen   0.5043\t(1.0 )\n",
      " in toto      0.7483\n",
      "> quit\n",
      "semanticdepparse(): e: quit  a: epsilon  p: epsilon\n",
      " lexical      -0.0296\t(-0.006 )\n",
      " semrole      -0.0238\t(0.0 )\n",
      " morph      0.0317\t(0.047 )\n",
      " morphgen   0.5142\t(1.0 )\n",
      " in toto      0.2136\n"
     ]
    }
   ],
   "source": [
    "command_loop(True,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function DependencyGraph.__init__.<locals>.<lambda> at 0x7fac3bff6048>,\n",
      "            {0: {'address': 0,\n",
      "                 'ctag': 'TOP',\n",
      "                 'deps': defaultdict(<class 'list'>, {'root': [2]}),\n",
      "                 'feats': None,\n",
      "                 'head': None,\n",
      "                 'lemma': None,\n",
      "                 'rel': None,\n",
      "                 'tag': 'TOP',\n",
      "                 'word': None},\n",
      "             1: {'address': 1,\n",
      "                 'ctag': 'PRP',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 2,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'nsubj',\n",
      "                 'tag': 'PRP',\n",
      "                 'word': 'we'},\n",
      "             2: {'address': 2,\n",
      "                 'ctag': 'VBP',\n",
      "                 'deps': defaultdict(<class 'list'>,\n",
      "                                     {'dobj': [4],\n",
      "                                      'nsubj': [1]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 0,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'root',\n",
      "                 'tag': 'VBP',\n",
      "                 'word': 'eat'},\n",
      "             3: {'address': 3,\n",
      "                 'ctag': 'DT',\n",
      "                 'deps': defaultdict(<class 'list'>, {}),\n",
      "                 'feats': '_',\n",
      "                 'head': 4,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'det',\n",
      "                 'tag': 'DT',\n",
      "                 'word': 'the'},\n",
      "             4: {'address': 4,\n",
      "                 'ctag': 'NN',\n",
      "                 'deps': defaultdict(<class 'list'>, {'det': [3]}),\n",
      "                 'feats': '_',\n",
      "                 'head': 2,\n",
      "                 'lemma': '_',\n",
      "                 'rel': 'dobj',\n",
      "                 'tag': 'NN',\n",
      "                 'word': 'fish'}})\n",
      "{'ctag': 'TOP', 'lemma': None, 'deps': defaultdict(<class 'list'>, {'root': [2]}), 'tag': 'TOP', 'head': None, 'rel': None, 'address': 0, 'feats': None, 'word': None}\n",
      "{'feats': '_', 'lemma': '_', 'address': 1, 'ctag': 'PRP', 'word': 'we', 'rel': 'nsubj', 'tag': 'PRP', 'head': 2, 'deps': defaultdict(<class 'list'>, {})}\n",
      "{'feats': '_', 'lemma': '_', 'address': 2, 'ctag': 'VBP', 'word': 'eat', 'rel': 'root', 'tag': 'VBP', 'head': 0, 'deps': defaultdict(<class 'list'>, {'nsubj': [1], 'dobj': [4]})}\n",
      "{'feats': '_', 'lemma': '_', 'address': 3, 'ctag': 'DT', 'word': 'the', 'rel': 'det', 'tag': 'DT', 'head': 4, 'deps': defaultdict(<class 'list'>, {})}\n",
      "{'feats': '_', 'lemma': '_', 'address': 4, 'ctag': 'NN', 'word': 'fish', 'rel': 'dobj', 'tag': 'NN', 'head': 2, 'deps': defaultdict(<class 'list'>, {'det': [3]})}\n"
     ]
    }
   ],
   "source": [
    "showtree(\"We eat the fish.\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
